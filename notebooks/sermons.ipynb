{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, re, shutil,json, sys\n",
    "import pandas as pd \n",
    "TCP = '/Users/amycweng/DH/TCP'\n",
    "sys.path.append('../')\n",
    "\n",
    "def findTextTCP(id):\n",
    "    if re.match('B1|B4',id[0:2]):\n",
    "        path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    else: \n",
    "        if f'{id}.P4.xml' in os.listdir(f'{TCP}/P1{id[0:2]}'):\n",
    "            path = f'{TCP}/P1{id[0:2]}/{id}.P4.xml'\n",
    "        elif f'{id}.P4.xml' in os.listdir(f'{TCP}/P2{id[0:2]}'): \n",
    "            path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    return path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find texts that contain sermons (DIV tag with attribute \"TYPE\"='sermon' or containing key terms in the title or subject headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "def is_sermon(filepath):\n",
    "    # read the input XML file \n",
    "    with open(filepath,'r') as file: \n",
    "        data = file.read()\n",
    "    # use soupstrainer to only parse the main body\n",
    "    tag = SoupStrainer(\"DIV1\")\n",
    "    soup = BeautifulSoup(data,features=\"xml\",parse_only=tag)\n",
    "    sermons = soup.findAll(attrs={\"TYPE\": \"sermon\"})\n",
    "    if len(sermons) > 0:      \n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "sermons = []\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        if tcpID == \"id\": continue\n",
    "        filepath = findTextTCP(tcpID)\n",
    "        if is_sermon(filepath): \n",
    "            subject_headings = data['keywords'][idx].replace(\" -- \",\"; \").replace(\"  \",\" \")\n",
    "            sermons.append( {\"id\": tcpID, \n",
    "                            \"estc\":data['estc'][idx],\n",
    "                            \"stc\":data['stc'][idx],\n",
    "                            \"title\": data['title'][idx],\n",
    "                            \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                            \"publisher\": data['publisher'][idx],\n",
    "                            \"pubplace\":data['pubplace'][idx],\n",
    "                            \"subject_headings\":subject_headings,\n",
    "                            \"date\":data['date'][idx]\n",
    "                            }\n",
    "            )\n",
    "    print(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4239 TCP XML files contain sermons.\n"
     ]
    }
   ],
   "source": [
    "# store relevant metadata in a CSV file \n",
    "with open(\"../assets/sermons.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=sermons[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sermons)\n",
    "\n",
    "print(f\"{len(sermons)} TCP XML files contain sermons.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sermons_metadata = pd.read_csv(\"../assets/sermons.csv\")\n",
    "sermons = sermons_metadata[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5839\n"
     ]
    }
   ],
   "source": [
    "# Find the texts that most likely contain sermons but do not have the proper div tag in the XML \n",
    "\n",
    "import os \n",
    "import pandas as pd \n",
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "texts = {}\n",
    "by_subj, by_title, by_both = [],[],[]\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        title = data['title'][idx]\n",
    "        clean_title = title.lower().replace(\"'\",'')\n",
    "        subject_headings = data['keywords'][idx]\n",
    "        unique_subjects = \" -- \".join(set(subject_headings.split(\" -- \")))\n",
    "        subject_hit, title_hit = False, False\n",
    "        if re.search('sermon', subject_headings.lower()): \n",
    "            subject_hit = True \n",
    "        if re.search(r'sermon|preached|preacht|preachd', clean_title): \n",
    "            title_hit = True\n",
    "        if subject_hit and title_hit: \n",
    "            by_both.append(tcpID)\n",
    "        elif subject_hit: \n",
    "            by_subj.append(tcpID)\n",
    "        elif title_hit: \n",
    "            by_title.append(tcpID)\n",
    "        if subject_hit or title_hit:  \n",
    "            texts[tcpID] =  {\"id\": tcpID, \n",
    "                            \"estc\":data['estc'][idx],\n",
    "                            \"stc\":data['stc'][idx],\n",
    "                            \"title\": data['title'][idx],\n",
    "                            \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                            \"publisher\": data['publisher'][idx],\n",
    "                            \"pubplace\":data['pubplace'][idx],\n",
    "                            \"subject_headings\":unique_subjects,\n",
    "                            \"date\":data['date'][idx]\n",
    "                            }\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4235\n"
     ]
    }
   ],
   "source": [
    "new = []\n",
    "sermons = {k:None for k in sermons}\n",
    "import os \n",
    "import pandas as pd \n",
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        if tcpID in sermons: \n",
    "            title = data['title'][idx]\n",
    "            clean_title = title.lower().replace(\"'\",'')\n",
    "            subject_headings = data['keywords'][idx]\n",
    "            unique_subjects = \" -- \".join(set(subject_headings.split(\" -- \")))  \n",
    "            new.append({\"id\": tcpID, \n",
    "                        \"estc\":data['estc'][idx],\n",
    "                        \"stc\":data['stc'][idx],\n",
    "                        \"title\": data['title'][idx],\n",
    "                        \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                        \"publisher\": data['publisher'][idx],\n",
    "                        \"pubplace\":data['pubplace'][idx],\n",
    "                        \"subject_headings\":unique_subjects,\n",
    "                        \"date\":data['date'][idx]\n",
    "                        })\n",
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=new[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sermons = {tcpID:0 for tcpID in sermons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_b, missing_s, missing_t = [],[],[]\n",
    "missing = {0:[], 1:[], 2:[]}\n",
    "for idx, collection in enumerate([by_both, by_subj, by_title]): \n",
    "    for tcpID in collection: \n",
    "        if tcpID not in sermons: missing[idx].append(tcpID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081 313 393\n"
     ]
    }
   ],
   "source": [
    "print(len(missing[0]),len(missing[1]),len(missing[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['B01388', 'A89416', 'B28836', 'B26622', 'B12473', 'B03839', 'B06138', 'B09463', 'A89104', 'A83012', 'A81906', 'A84063', 'A81606', 'A88596', 'A81417', 'A85341', 'A90702', 'A96864', 'A93332', 'A90476', 'A95939', 'A79568', 'A73832', 'A77100', 'A63877', 'A62992', 'A67411', 'A60864', 'A64639', 'A64197', 'A61683', 'A48191', 'A43685', 'A43806', 'A46883', 'A40538', 'A41496', 'A45149', 'A48968', 'A56791', 'A55289', 'A54939', 'A57258', 'A56278', 'A58892', 'A16497', 'A18267', 'A03696', 'A06013', 'A31039', 'A60568', 'A64394', 'A68546', 'A65419', 'A77638', 'A78013', 'A42577', 'A47973', 'A42539', 'A45574', 'A00164', 'A00156', 'A09418', 'A11848', 'A18019', 'A13299', 'A14927', 'A30903', 'A36190', 'A31459', 'A26859', 'A26426', 'A26065']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 393)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_texts = []\n",
    "title_only = []\n",
    "for idx, collection in missing.items(): \n",
    "    ''' \n",
    "    Exclude the missing TCP ids that only have key terms in the title but not the subject headings.\n",
    "    These are the ones that are most likely to be false positives. \n",
    "    '''\n",
    "    if idx == 2: \n",
    "        for tcpID in collection: \n",
    "            title_only.append(texts[tcpID]) \n",
    "    else: \n",
    "        for tcpID in collection: \n",
    "            if tcpID in exclude: continue\n",
    "            missing_texts.append(texts[tcpID])\n",
    "len(missing_texts), len(title_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in texts.values(): \n",
    "    t = t[\"id\"]\n",
    "    path = findTextTCP(t)\n",
    "    shutil.copy(path,'/Users/amycweng/DH/sermonsTCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = []\n",
    "for t in title_only: \n",
    "    tcpID = t[\"id\"]\n",
    "    title = t[\"title\"]\n",
    "    subjects = t[\"subject_headings\"]\n",
    "    if tcpID in sermons: continue\n",
    "    if tcpID in exclude: \n",
    "        unknown.append(texts[tcpID])\n",
    "        continue\n",
    "    if re.search(\"answer|aunswer|ansvvere\",title):\n",
    "        if not re.search(\"substance of\", title): \n",
    "            unknown.append(texts[tcpID])\n",
    "        else: \n",
    "            missing_texts.append(texts[tcpID])\n",
    "    elif re.search('sermon',title): \n",
    "        missing_texts.append(texts[tcpID])\n",
    "    else: \n",
    "        unknown.append(texts[tcpID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587 165\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_texts), len(unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons_missing.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=missing_texts[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(missing_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons_unknown.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=unknown[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(unknown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
