{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, re, shutil,json, sys\n",
    "import pandas as pd \n",
    "TCP = '/Users/amycweng/DH/TCP'\n",
    "sys.path.append('../')\n",
    "\n",
    "def findTextTCP(id):\n",
    "    if re.match('B1|B4',id[0:2]):\n",
    "        path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    else: \n",
    "        if f'{id}.P4.xml' in os.listdir(f'{TCP}/P1{id[0:2]}'):\n",
    "            path = f'{TCP}/P1{id[0:2]}/{id}.P4.xml'\n",
    "        elif f'{id}.P4.xml' in os.listdir(f'{TCP}/P2{id[0:2]}'): \n",
    "            path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    return path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find texts that contain sermons (DIV tag with attribute \"TYPE\"='sermon' or containing key terms in the title or subject headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "def is_sermon(filepath):\n",
    "    # read the input XML file \n",
    "    with open(filepath,'r') as file: \n",
    "        data = file.read()\n",
    "    # use soupstrainer to only parse the main body\n",
    "    tag = SoupStrainer(\"DIV1\")\n",
    "    soup = BeautifulSoup(data,features=\"xml\",parse_only=tag)\n",
    "    sermons = soup.findAll(attrs={\"TYPE\": \"sermon\"})\n",
    "    if len(sermons) > 0:      \n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "sermons = []\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        if tcpID == \"id\": continue\n",
    "        filepath = findTextTCP(tcpID)\n",
    "        if is_sermon(filepath): \n",
    "            subject_headings = data['keywords'][idx].replace(\" -- \",\"; \").replace(\"  \",\" \")\n",
    "            sermons.append( {\"id\": tcpID, \n",
    "                            \"estc\":data['estc'][idx],\n",
    "                            \"stc\":data['stc'][idx],\n",
    "                            \"title\": data['title'][idx],\n",
    "                            \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                            \"publisher\": data['publisher'][idx],\n",
    "                            \"pubplace\":data['pubplace'][idx],\n",
    "                            \"subject_headings\":subject_headings,\n",
    "                            \"date\":data['date'][idx]\n",
    "                            }\n",
    "            )\n",
    "    print(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4239 TCP XML files contain sermons.\n"
     ]
    }
   ],
   "source": [
    "# store relevant metadata in a CSV file \n",
    "with open(\"../assets/sermons.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=sermons[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sermons)\n",
    "\n",
    "print(f\"{len(sermons)} TCP XML files contain sermons.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sermons_metadata = pd.read_csv(\"../assets/sermons.csv\")\n",
    "sermons = sermons_metadata[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5839\n"
     ]
    }
   ],
   "source": [
    "# Find the texts that most likely contain sermons but do not have the proper div tag in the XML \n",
    "\n",
    "import os \n",
    "import pandas as pd \n",
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "texts = {}\n",
    "by_subj, by_title, by_both = [],[],[]\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        title = data['title'][idx]\n",
    "        clean_title = title.lower().replace(\"'\",'')\n",
    "        subject_headings = data['keywords'][idx]\n",
    "        unique_subjects = \" -- \".join(set(subject_headings.split(\" -- \")))\n",
    "        subject_hit, title_hit = False, False\n",
    "        if re.search('sermon', subject_headings.lower()): \n",
    "            subject_hit = True \n",
    "        if re.search(r'sermon|preached|preacht|preachd', clean_title): \n",
    "            title_hit = True\n",
    "        if subject_hit and title_hit: \n",
    "            by_both.append(tcpID)\n",
    "        elif subject_hit: \n",
    "            by_subj.append(tcpID)\n",
    "        elif title_hit: \n",
    "            by_title.append(tcpID)\n",
    "        if subject_hit or title_hit:  \n",
    "            texts[tcpID] =  {\"id\": tcpID, \n",
    "                            \"estc\":data['estc'][idx],\n",
    "                            \"stc\":data['stc'][idx],\n",
    "                            \"title\": data['title'][idx],\n",
    "                            \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                            \"publisher\": data['publisher'][idx],\n",
    "                            \"pubplace\":data['pubplace'][idx],\n",
    "                            \"subject_headings\":unique_subjects,\n",
    "                            \"date\":data['date'][idx]\n",
    "                            }\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4235\n"
     ]
    }
   ],
   "source": [
    "new = []\n",
    "sermons = {k:None for k in sermons}\n",
    "import os \n",
    "import pandas as pd \n",
    "metadataFolder = '/Users/amycweng/DH/ECBC-Data-2022/TCP metadata'\n",
    "for csvFile in os.listdir(metadataFolder):\n",
    "    data = pd.read_csv(os.path.join(metadataFolder,csvFile))\n",
    "    for idx,tcpID in enumerate(data['id']):\n",
    "        if tcpID in sermons: \n",
    "            title = data['title'][idx]\n",
    "            clean_title = title.lower().replace(\"'\",'')\n",
    "            subject_headings = data['keywords'][idx]\n",
    "            unique_subjects = \" -- \".join(set(subject_headings.split(\" -- \")))  \n",
    "            new.append({\"id\": tcpID, \n",
    "                        \"estc\":data['estc'][idx],\n",
    "                        \"stc\":data['stc'][idx],\n",
    "                        \"title\": data['title'][idx],\n",
    "                        \"authors\": \"; \".join(set(data['author'][idx].split(\"; \"))),\n",
    "                        \"publisher\": data['publisher'][idx],\n",
    "                        \"pubplace\":data['pubplace'][idx],\n",
    "                        \"subject_headings\":unique_subjects,\n",
    "                        \"date\":data['date'][idx]\n",
    "                        })\n",
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=new[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sermons = {tcpID:0 for tcpID in sermons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_b, missing_s, missing_t = [],[],[]\n",
    "missing = {0:[], 1:[], 2:[]}\n",
    "for idx, collection in enumerate([by_both, by_subj, by_title]): \n",
    "    for tcpID in collection: \n",
    "        if tcpID not in sermons: missing[idx].append(tcpID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081 313 393\n"
     ]
    }
   ],
   "source": [
    "print(len(missing[0]),len(missing[1]),len(missing[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['B01388', 'A89416', 'B28836', 'B26622', 'B12473', 'B03839', 'B06138', 'B09463', 'A89104', 'A83012', 'A81906', 'A84063', 'A81606', 'A88596', 'A81417', 'A85341', 'A90702', 'A96864', 'A93332', 'A90476', 'A95939', 'A79568', 'A73832', 'A77100', 'A63877', 'A62992', 'A67411', 'A60864', 'A64639', 'A64197', 'A61683', 'A48191', 'A43685', 'A43806', 'A46883', 'A40538', 'A41496', 'A45149', 'A48968', 'A56791', 'A55289', 'A54939', 'A57258', 'A56278', 'A58892', 'A16497', 'A18267', 'A03696', 'A06013', 'A31039', 'A60568', 'A64394', 'A68546', 'A65419', 'A77638', 'A78013', 'A42577', 'A47973', 'A42539', 'A45574', 'A00164', 'A00156', 'A09418', 'A11848', 'A18019', 'A13299', 'A14927', 'A30903', 'A36190', 'A31459', 'A26859', 'A26426', 'A26065']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 393)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_texts = []\n",
    "title_only = []\n",
    "for idx, collection in missing.items(): \n",
    "    ''' \n",
    "    Exclude the missing TCP ids that only have key terms in the title but not the subject headings.\n",
    "    These are the ones that are most likely to be false positives. \n",
    "    '''\n",
    "    if idx == 2: \n",
    "        for tcpID in collection: \n",
    "            title_only.append(texts[tcpID]) \n",
    "    else: \n",
    "        for tcpID in collection: \n",
    "            if tcpID in exclude: continue\n",
    "            missing_texts.append(texts[tcpID])\n",
    "len(missing_texts), len(title_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in texts.values(): \n",
    "    t = t[\"id\"]\n",
    "    path = findTextTCP(t)\n",
    "    shutil.copy(path,'/Users/amycweng/DH/sermonsTCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = []\n",
    "for t in title_only: \n",
    "    tcpID = t[\"id\"]\n",
    "    title = t[\"title\"]\n",
    "    subjects = t[\"subject_headings\"]\n",
    "    if tcpID in sermons: continue\n",
    "    if tcpID in exclude: \n",
    "        unknown.append(texts[tcpID])\n",
    "        continue\n",
    "    if re.search(\"answer|aunswer|ansvvere\",title):\n",
    "        if not re.search(\"substance of\", title): \n",
    "            unknown.append(texts[tcpID])\n",
    "        else: \n",
    "            missing_texts.append(texts[tcpID])\n",
    "    elif re.search('sermon',title): \n",
    "        missing_texts.append(texts[tcpID])\n",
    "    else: \n",
    "        unknown.append(texts[tcpID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587 165\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_texts), len(unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons_missing.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=missing_texts[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(missing_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/sermons_unknown.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=unknown[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map section names to indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5862/5862 [00:03<00:00, 1927.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcpID</th>\n",
       "      <th>section_idx</th>\n",
       "      <th>section_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A57739</td>\n",
       "      <td>0</td>\n",
       "      <td>title_page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A57739</td>\n",
       "      <td>1</td>\n",
       "      <td>to_the_reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A57739</td>\n",
       "      <td>2</td>\n",
       "      <td>sermon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A67822</td>\n",
       "      <td>0</td>\n",
       "      <td>title_page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A67822</td>\n",
       "      <td>1</td>\n",
       "      <td>translator_to_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35126</th>\n",
       "      <td>A41142</td>\n",
       "      <td>2</td>\n",
       "      <td>letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35127</th>\n",
       "      <td>A41142</td>\n",
       "      <td>3</td>\n",
       "      <td>to_the_reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35128</th>\n",
       "      <td>A41142</td>\n",
       "      <td>4</td>\n",
       "      <td>table_of_contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35129</th>\n",
       "      <td>A41142</td>\n",
       "      <td>5</td>\n",
       "      <td>sermon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35130</th>\n",
       "      <td>A41142</td>\n",
       "      <td>6</td>\n",
       "      <td>errata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tcpID section_idx          section_name\n",
       "0      A57739           0            title_page\n",
       "1      A57739           1         to_the_reader\n",
       "2      A57739           2                sermon\n",
       "3      A67822           0            title_page\n",
       "4      A67822           1  translator_to_author\n",
       "...       ...         ...                   ...\n",
       "35126  A41142           2                letter\n",
       "35127  A41142           3         to_the_reader\n",
       "35128  A41142           4     table_of_contents\n",
       "35129  A41142           5                sermon\n",
       "35130  A41142           6                errata\n",
       "\n",
       "[35131 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,re\n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "\n",
    "sermons_metadata = pd.read_csv(\"../assets/sermons.csv\")\n",
    "sermons = list(sermons_metadata[\"id\"])\n",
    "missing_sermons = pd.read_csv(\"../assets/sermons_missing.csv\")\n",
    "sermons.extend(list(missing_sermons[\"id\"]))\n",
    "sermons = {s:None for s in sermons}\n",
    "num_oral = 0 \n",
    "sections = [] # tcpID to section to index \n",
    "for fp in tqdm(os.listdir(\"../assets/plain_all\")): \n",
    "    if fp == \".DS_Store\": continue \n",
    "    with open(f\"../assets/plain_all/{fp}\",\"r\") as file: \n",
    "        text = file.read()\n",
    "    tcpID = fp.split(\".\")[0]\n",
    "    if tcpID not in sermons: continue \n",
    "    s = re.findall(r\"SECTION(\\d+):(\\w+)\\b\",text)\n",
    "    for idx, name in s: \n",
    "        if re.search(r\"sermon|speech|oratio|homil|eulog|lecture|encomi|exhortation|memorial|consolatio\",name):\n",
    "            num_oral += 1  \n",
    "        sections.append({\"tcpID\":tcpID, \"section_idx\":idx,\"section_name\":name})\n",
    "sections = pd.DataFrame(sections)\n",
    "sections.to_csv('/Users/amycweng/DH/SERMONS_APP/db/data/sections.csv',header=False,index=False)\n",
    "print(num_oral)\n",
    "sections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
