{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-extract subject headings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, os \n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from tqdm import tqdm  \n",
    "import pandas as pd \n",
    "TCP = '/Users/amycweng/DH/TCP'\n",
    "sys.path.append('../')\n",
    "\n",
    "def findTextTCP(id):\n",
    "    if re.match('B1|B4',id[0:2]):\n",
    "        path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    else: \n",
    "        if f'{id}.P4.xml' in os.listdir(f'{TCP}/P1{id[0:2]}'):\n",
    "            path = f'{TCP}/P1{id[0:2]}/{id}.P4.xml'\n",
    "        elif f'{id}.P4.xml' in os.listdir(f'{TCP}/P2{id[0:2]}'): \n",
    "            path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    return path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A27574: 100%|██████████| 5729/5729 [04:13<00:00, 22.60it/s]\n"
     ]
    }
   ],
   "source": [
    "sermons = list(pd.read_csv(\"../assets/sermons.csv\")['id'])\n",
    "sermons.extend(list(pd.read_csv(\"../assets/sermons_missing.csv\")[\"id\"]))\n",
    "tcpID_subjects = {}\n",
    "progress_bar = tqdm(sermons)\n",
    "for file in progress_bar:\n",
    "    progress_bar.set_description(file)\n",
    "    tcpID = file.split(\".\")[0]\n",
    "    tcpID_subjects[tcpID] = []\n",
    "    filepath = findTextTCP(tcpID)\n",
    "\n",
    "    # read the input XML file \n",
    "    with open(filepath,'r',encoding='utf-8') as file: \n",
    "        data = file.read()\n",
    "    # use soupstrainer to only parse the main body\n",
    "    tag = SoupStrainer(\"KEYWORDS\")\n",
    "    soup = BeautifulSoup(data,features=\"xml\",parse_only=tag)\n",
    "    \n",
    "    subjects = soup.find_all(['TERM'])\n",
    "    for s in subjects: \n",
    "        tcpID_subjects[tcpID].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcpID_subjects = {k:[item.string for item in v] for k,v in tcpID_subjects.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def correct_metadata_file(fp):\n",
    "    sermons = pd.read_csv(fp)\n",
    "    sermons = sermons.to_dict(orient='records')\n",
    "    new_sermons = []\n",
    "    for info_dict in tqdm(sermons):\n",
    "        tcpID = info_dict['id']\n",
    "        filepath = findTextTCP(tcpID)\n",
    "        if re.search(f'TCP/P1',filepath): \n",
    "            phase = \"1\"\n",
    "        else: \n",
    "            phase = \"2\"\n",
    "        info_dict['phase'] = phase\n",
    "        new_sermons.append(info_dict)\n",
    "    new_sermons = pd.DataFrame(new_sermons)\n",
    "    new_sermons.to_csv(fp,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4226/4226 [00:29<00:00, 142.88it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_metadata_file(\"../assets/sermons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1503/1503 [00:08<00:00, 169.77it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_metadata_file(\"../assets/sermons_missing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5729/5729 [00:00<00:00, 201419.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter \n",
    "from tqdm import tqdm \n",
    "import re \n",
    "\n",
    "sermons = pd.read_csv(\"/Users/amycweng/DH/SERMONS_APP/db/data/sermons.csv\",header=None)\n",
    "sermons = sermons.to_dict(orient='records')\n",
    "\n",
    "missing = pd.read_csv(\"/Users/amycweng/DH/SERMONS_APP/db/data/sermons_missing.csv\",header=None)\n",
    "missing = missing.to_dict(orient='records')\n",
    "sermons.extend(missing)\n",
    "\n",
    "export = []\n",
    "all_subjects = []\n",
    "\n",
    "for info_dict in tqdm(sermons):\n",
    "    subjects = info_dict[7]\n",
    "    if not isinstance(subjects,str): continue  \n",
    "    seen = {}\n",
    "    for w in subjects.split(\"; \"): \n",
    "        if w == \"No Keywords\": continue\n",
    "        if w != 'O.T.' and w!= 'N.T.': \n",
    "            w = w.strip(\".\")\n",
    "        # w = re.sub(r\"\\s+\",\" \",w)\n",
    "        # w = re.sub(\" -- Early works to 1800\",\"\",w)\n",
    "        # w = re.sub(r\"\\s+\",\" \",w)\n",
    "        # w = re.sub(\" -- 16th century| -- 17th century\",\"\",w)\n",
    "        # w = re.sub(r\"\\s+\",\" \",w)\n",
    "        # w = re.sub(\" -- Sermons\",\"\",w)\n",
    "        # w = re.sub(r\"\\s+\",\" \",w)\n",
    "        # w = re.sub(\"Great Britain -- History -- \",\"\",w)\n",
    "        # w = re.sub(r\"\\s+\",\" \",w)\n",
    "        all_subjects.append(w)\n",
    "        if w not in seen: \n",
    "            seen[w] = True \n",
    "            export.append({'tcpID':info_dict[0],'subject':w})\n",
    "\n",
    "processed = {}\n",
    "for w, freq in sorted(dict(Counter(all_subjects)).items(),key=lambda x:x[1],reverse=True):\n",
    "    if w not in processed: processed[w] = freq\n",
    "    else: processed[w] += freq\n",
    "import json,csv \n",
    "outputfolder = \"/Users/amycweng/DH/SERMONS_APP/db/data\"\n",
    "\n",
    "with open(f\"{outputfolder}/subjects.json\",\"w+\") as file: \n",
    "    json.dump(sorted(processed.items(),key=lambda x:x[1],reverse=True),file)\n",
    "with open(f\"{outputfolder}/subjects.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=export[0].keys())\n",
    "    writer.writerows(export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
