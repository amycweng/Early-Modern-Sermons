{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6502d6e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf64de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json,re\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350208",
   "metadata": {},
   "source": [
    "## Bible books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da58dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_books = {\n",
    "    'Gen': 'Genesis',\n",
    "    'Exo': 'Exodus',\n",
    "    'Lev': 'Leviticus',\n",
    "    'Num': 'Numbers',\n",
    "    'Deu': 'Deuteronomy',\n",
    "    'Jos': 'Joshua',\n",
    "    'Jdg': 'Judges',\n",
    "    'Rut': 'Ruth',\n",
    "    '1Sa': '1 Samuel',\n",
    "    '2Sa': '2 Samuel',\n",
    "    '1Ki': '1 Kings',\n",
    "    '2Ki': '2 Kings',\n",
    "    '1Ch': '1 Chronicles',\n",
    "    '2Ch': '2 Chronicles',\n",
    "    'Ezr': 'Ezra',\n",
    "    'Neh':'Nehemiah',\n",
    "    'Est': 'Esther',\n",
    "    'Job': 'Job',\n",
    "    'Psa': 'Psalms',\n",
    "    'Pro': 'Proverbs',\n",
    "    'Ecc': 'Ecclesiastes',\n",
    "    'Sng': 'Canticles',\n",
    "    'Isa': 'Isaiah',\n",
    "    'Jer': 'Jeremiah',\n",
    "    'Lam': 'Lamentations',\n",
    "    'Ezk': 'Ezekiel',\n",
    "    'Dan': 'Daniel',\n",
    "    'Hos': 'Hosea',\n",
    "    'Jol': 'Joel',\n",
    "    'Amo': 'Amos',\n",
    "    'Oba': 'Obadiah',\n",
    "    'Jon': 'Jonah',\n",
    "    'Mic': 'Micah',\n",
    "    'Nam': 'Nahum',\n",
    "    'Hab': 'Habakkuk',\n",
    "    'Zep': 'Zephaniah',\n",
    "    'Hag': 'Haggai',\n",
    "    'Zec': 'Zechariah',\n",
    "    'Mal': 'Malachi',\n",
    "    'Mat': 'Matthew',\n",
    "    'Mrk': 'Mark',\n",
    "    'Luk': 'Luke',\n",
    "    'Jhn': 'John',\n",
    "    'Act': 'Acts',\n",
    "    'Rom': 'Romans',\n",
    "    '1Co': '1 Corinthians',\n",
    "    '2Co': '2 Corinthians',\n",
    "    'Gal': 'Galatians',\n",
    "    'Eph': 'Ephesians',\n",
    "    'Php': 'Philippians',\n",
    "    'Col': 'Colossians',\n",
    "    '1Th': '1 Thessalonians',\n",
    "    '2Th': '2 Thessalonians',\n",
    "    '1Ti': '1 Timothy',\n",
    "    '2Ti': '2 Timothy',\n",
    "    'Tit': 'Titus',\n",
    "    'Phm': 'Philemon',\n",
    "    'Heb': 'Hebrews',\n",
    "    'Jas': 'James',\n",
    "    '1Pe': '1 Peter',\n",
    "    '2Pe': '2 Peter',\n",
    "    '1Jn': '1 John',\n",
    "    '2Jn': '2 John',\n",
    "    '3Jn': '3 John',\n",
    "    'Jud': 'Jude',\n",
    "    'Rev': 'Revelation',\n",
    "    'Sus': \"Susanna\",\n",
    "    'Bel':\"Bel and the Dragon\",\n",
    "    'Bar':'Baruch',\n",
    "    'Sir':'Ecclesiasticus',\n",
    "    'Wis':'Wisdom',\n",
    "    '1Ma':'1 Maccabees',\n",
    "    '2Ma':'2 Maccabees',\n",
    "    '1Es':\"1 Esdras\",\n",
    "    '2Es':'2 Esdras',\n",
    "    'Tob':'Tobit',\n",
    "    'Jdt':'Judith',\n",
    "    '4Ma':'4 Maccabees',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f4b76",
   "metadata": {},
   "source": [
    "## Load Bibles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c7f2247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36702/36702 [00:01<00:00, 27118.41it/s]\n",
      "100%|██████████| 31090/31090 [00:01<00:00, 27618.25it/s]\n",
      "100%|██████████| 14737/14737 [00:00<00:00, 29539.53it/s]\n",
      "100%|██████████| 35811/35811 [00:00<00:00, 37624.93it/s]\n",
      "100%|██████████| 7954/7954 [00:00<00:00, 28110.01it/s]\n",
      "100%|██████████| 9622/9622 [00:00<00:00, 26201.50it/s]\n",
      "100%|██████████| 35809/35809 [00:01<00:00, 30751.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "276627"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../assets/Bibles/ESV.json\") as file: \n",
    "    ESV = json.load(file)\n",
    "    \n",
    "bible = {}\n",
    "\n",
    "b_versions = ['AKJV','Geneva', 'ODRV','Douay-Rheims', 'Tyndale', 'Wycliffe','Vulgate']\n",
    "for bname in b_versions:\n",
    "    data = pd.read_csv(f\"../assets/Bibles/{bname}.csv\",header=None)\n",
    "    data = data.to_dict(orient=\"records\")\n",
    "    for entry in tqdm(data):\n",
    "        key = entry[0]\n",
    "        v_id = key.split(\" (\")[0]\n",
    "        text = entry[6]\n",
    "        if re.search(\"Douay-Rheims\",key):\n",
    "            if re.sub(\"Douay-Rheims\",\"ODRV\",key) in bible: continue\n",
    "        if len(text.split(\" \")) < 200:\n",
    "            bible[key] = f\"{v_id} {text}\"\n",
    "\n",
    "        parts = re.split(r'(?<=[\\.\\?]) (?=[A-Z])|(?<=[\\!\\:\\;])', text)\n",
    "        parts = [re.sub(r'\\s+', ' ', p).strip() for p in parts if len(p.strip(\" \")) > 0]\n",
    "        if (len(parts[0].split(\" \")) <= 5 or len(parts[-1].split(\" \")) <= 5 or re.search(r\"\\&\\w+\\;\",parts[0])): \n",
    "            for pidx, p in enumerate(parts): continue\n",
    "        elif len(parts) > 1:  \n",
    "            for pidx, p in enumerate(parts):\n",
    "              p_id = f\"{key} - {pidx}\"\n",
    "              if len(p) == 0: continue\n",
    "              if re.search(r\"\\&\\w+\\;\",p) or len(p.split(\" \")) <= 5: continue\n",
    "              bible[p_id] = f\"Part {pidx+1} of {v_id}: {p}\"\n",
    "bible_verses = list(bible.values())\n",
    "bible_ids = list(bible.keys())\n",
    "id_to_idx = {v_id:idx for idx, v_id in enumerate(bible_ids)}\n",
    "len(bible_verses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14b0c9",
   "metadata": {},
   "source": [
    "# Versification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c7e96",
   "metadata": {},
   "source": [
    "## Get verse mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf1045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblical entities \n",
    "with open(f\"../assets/Bibles/TVTMS - Translators Versification Traditions with Methodology for Standardisation for Eng+Heb+Lat+Grk+Others - STEPBible.org CC BY.txt\") as file: \n",
    "    data = file.readlines()\n",
    "in_section = False\n",
    "KJV = None \n",
    "Latin = None \n",
    "mappings = {} # AKJV to Latin \n",
    "abbrev = {}\n",
    "for idx, line in enumerate(data): \n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    \n",
    "    if re.search(r\"\\$[\\d\\w]+\\.\\d+\\:\",line):\n",
    "        line = line.split(\"\\t\")\n",
    "        KJV, Latin = None, None \n",
    "        for idx, item in enumerate(line): \n",
    "            if item == \"English KJV\": \n",
    "                KJV = idx \n",
    "            elif item == \"Latin\": \n",
    "                Latin = idx \n",
    "         \n",
    "    elif re.search(r\"OneToOne\\t[\\d\\w]+\\.\\d+\",line) or re.search(\"MergedPrevVerse|SubdividedVerse\",line):\n",
    "        if KJV is None or Latin is None: continue\n",
    "        line = line.split(\"\\t\")\n",
    "        abbrev[line[KJV].split(\".\")[0]] = None \n",
    "        KJV_id = re.findall(r\"([\\d\\w]+)\\.(\\d+):(\\d+)[-]*(.*?)$\",line[KJV])\n",
    "        if len(KJV_id) == 0: continue \n",
    "        KJV_id = list(KJV_id[0])\n",
    "        Latin_id = re.findall(r\"([\\d\\w]+)\\.(\\d+):(\\d+)[-]*(.*?)$\",line[Latin])\n",
    "        if len(Latin_id) == 0: continue \n",
    "        Latin_id = list(Latin_id[0])\n",
    "        if \".\" in Latin_id[-1]: Latin_id[-1] = ''\n",
    "        if \".\" in KJV_id[-1]: KJV_id[-1] = ''\n",
    "        \n",
    "        if Latin_id[0] not in corrected_books: continue \n",
    "        if KJV_id[0] not in corrected_books: continue \n",
    "        \n",
    "        KJV_id[0] = corrected_books[KJV_id[0]]\n",
    "        Latin_id[0] = corrected_books[Latin_id[0]]\n",
    "        final_KJV_id = f\"{KJV_id[0]} {KJV_id[1]}.{KJV_id[2]}\"\n",
    "        final_Latin_id = f\"{Latin_id[0]} {Latin_id[1]}.{Latin_id[2]}\"\n",
    "\n",
    "        if Latin_id[-1] == \"]\":\n",
    "            mappings[final_KJV_id] = None \n",
    "            continue \n",
    "        \n",
    "        if len(KJV_id[-1]) == 0: \n",
    "            if final_KJV_id == final_Latin_id: continue \n",
    "            mappings[final_KJV_id] = final_Latin_id\n",
    "        else: \n",
    "            KJV_nums = [i for i in range(int(KJV_id[-2]),int(KJV_id[-1])+1)]\n",
    "            Latin_nums = [i for i in range(int(Latin_id[-2]),int(Latin_id[-1])+1)]\n",
    "            for idx, i in enumerate(KJV_nums): \n",
    "                final_KJV_id = f\"{KJV_id[0]} {KJV_id[1]}.{i}\"\n",
    "                final_Latin_id = f\"{Latin_id[0]} {Latin_id[1]}.{Latin_nums[idx]}\"\n",
    "                if final_KJV_id == final_Latin_id: continue\n",
    "                mappings[final_KJV_id] = final_Latin_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b596d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/Bibles/verse_mapping.json\",'w+') as file: \n",
    "    json.dump(mappings, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f287d0",
   "metadata": {},
   "source": [
    "## Parallel Verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1bcb6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "folder = \"../..\"\n",
    "\n",
    "fname = \"parallel_verses_UNCONFIDENT - HNDPR\"\n",
    "parallel = pd.read_csv(f\"{folder}/QP/{fname}.csv\").fillna('')\n",
    "parallel = parallel.to_dict(orient='records')\n",
    "for item in parallel: \n",
    "    item['text'] = item['ESV'] + \" \" + item['text']\n",
    "\n",
    "with open(f\"{folder}/QP/predictions/{fname}_DSV3.json\",'r') as f: \n",
    "    responses = json.load(f) \n",
    "with open(f\"../assets/Bibles/verse_mapping.json\",'r') as f: \n",
    "    mapping = json.load(f) \n",
    "\n",
    "def fix_name(v_id, v2_id):\n",
    "  if \"1 Kings\" in v_id and \"1 Kings\" in v2_id: v_id = \"3 Kings\" + v_id.split(\"1 Kings\")[-1]\n",
    "  elif \"2 Kings\" in v_id and \"2 Kings\" in v2_id: v_id = \"4 Kings\" + v_id.split(\"2 Kings\")[-1]\n",
    "  elif \"1 Samuel\" in v_id and \"1 Samuel\" in v2_id: v_id = \"1 Kings\" + v_id.split(\"1 Samuel\")[-1]\n",
    "  elif \"2 Samuel\" in v_id and \"2 Samuel\" in v2_id: v_id = \"2 Kings\" + v_id.split(\"2 Samuel\")[-1]\n",
    "  elif re.search(r\"^\\d+ Chronicles\",v_id): v_id = re.sub(r\"Chronicles\",\"Paralipomenon\",v_id)\n",
    "  return v_id\n",
    "\n",
    "def fix_name_revert(v_id):\n",
    "  if \"3 Kings\" in v_id: v_id = \"1 Kings\" + v_id.split(\"3 Kings\")[-1]\n",
    "  elif \"4 Kings\" in v_id: v_id = \"2 Kings\" + v_id.split(\"4 Kings\")[-1]\n",
    "  elif \"1 Kings\" in v_id: v_id = \"1 Samuel\" + v_id.split(\"1 Kings\")[-1]\n",
    "  elif \"2 Kings\" in v_id: v_id = \"2 Samuel\" + v_id.split(\"2 Kings\")[-1]\n",
    "  elif re.search(r\"^\\d+ Paralipomenon\",v_id): v_id = re.sub(r\"Paralipomenon\",\"Chronicles\",v_id)\n",
    "  return v_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10067cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daniel 4.7'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['Daniel 4.10']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed2990",
   "metadata": {},
   "source": [
    "### HNDPR Unconfident "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = {}\n",
    "num_mapped = 0\n",
    "new_mapping = {}\n",
    "for idx, item in enumerate(parallel):\n",
    "    key = \"{}; {} ({})\".format(item['ESV'], item['Parallel'], item['version'])\n",
    "    if key in responses: continue \n",
    "    if item['ESV'] not in new_mapping: \n",
    "      new_mapping[item['ESV']] = []\n",
    "\n",
    "    p_id = item['Parallel']\n",
    "    if item['version'] in ['Douay-Rheims','ODRV','Vulgate','Wycliffe']: \n",
    "       p_id = fix_name_revert(p_id)\n",
    "    \n",
    "    full_id = item['Parallel'] + f\" ({item['version']})\"\n",
    "\n",
    "    if item['ESV'] == p_id and item['version'] in ['AKJV','Geneva','Tyndale']: \n",
    "      seen[item['ESV']] = True \n",
    "      new_mapping[item['ESV']].append(full_id)\n",
    "    elif item['ESV'] in mapping:\n",
    "      if item['version'] in ['Douay-Rheims','ODRV','Vulgate','Wycliffe']: \n",
    "        if mapping[item['ESV']] is None:\n",
    "          seen[item['ESV']] = True\n",
    "          # there is no equivalent in the Latin-based Bibles  \n",
    "        elif p_id == mapping[item['ESV']]: \n",
    "          new_mapping[item['ESV']].append(full_id)\n",
    "          seen[item['ESV']] = True  \n",
    "    elif item['ESV'] == p_id: \n",
    "        new_mapping[item['ESV']].append(full_id)\n",
    "        seen[item['ESV']] = True \n",
    "\n",
    "for key in responses: \n",
    "  key = key.split(\"; \")[0]\n",
    "  seen[key] = True \n",
    "\n",
    "not_seen = {}\n",
    "for idx, item in enumerate(parallel):\n",
    "    key = \"{}; {} ({})\".format(item['ESV'], item['Parallel'], item['version'])\n",
    "    if key in responses: continue \n",
    "    if item['ESV'] not in seen: \n",
    "      not_seen[(item['ESV'],item['version'])] = True \n",
    "\n",
    "for ESV_id, version in not_seen.keys(): \n",
    "  if item['ESV'] not in new_mapping: \n",
    "    new_mapping[item['ESV']] = []\n",
    "  if ESV_id not in mapping or version in ['AKJV','Geneva','Tyndale']: \n",
    "    new_mapping[ESV_id].append(ESV_id + f\" ({item['version']})\")\n",
    "  elif ESV_id in mapping:\n",
    "    if mapping[ESV_id] is None: continue \n",
    "    new_mapping[ESV_id].append(mapping[ESV_id] + f\" ({item['version']})\")\n",
    "\n",
    "new_mapping = {k:v for k,v in new_mapping.items() if len(v) >0}\n",
    "with open(f\"../assets/QP_Datasets/parallel_mapping_remainder.json\",'w+') as file: \n",
    "    json.dump(new_mapping,file)\n",
    "len(new_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a83075",
   "metadata": {},
   "source": [
    "### All "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f60e52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31129"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_parallel_data():\n",
    "    p_data = {}\n",
    "    with open(f\"{folder}/Early-Modern-Sermons/assets/QP_Datasets/confident_labeled.json\",'r') as file:\n",
    "      labeled_dict = json.load(file)\n",
    "    for ESV_id, pv_list in labeled_dict.items():\n",
    "      pv_list = list(set(pv_list))\n",
    "      p_data[ESV_id] = {'qid': ESV_id,\n",
    "                        'pos':{k:None for k in pv_list}, # verse ids with version,\n",
    "                        }\n",
    "    with open(f\"{folder}/Early-Modern-Sermons/assets/QP_Datasets/parallel_mapping_remainder.json\",'r') as file: \n",
    "      parallel = json.load(file)\n",
    "    for v_id,vlist in parallel.items():\n",
    "      if v_id in labeled_dict: continue\n",
    "      if v_id not in p_data:\n",
    "        p_data[v_id] = {'qid': v_id,\n",
    "                        'pos':{}, # high similarity and equivalent numberings\n",
    "                        } \n",
    "      for v in vlist: \n",
    "        p_data[v_id]['pos'][v] = None \n",
    "    \n",
    "    training_set = {}\n",
    "    for key, entry in p_data.items():\n",
    "      entry['pos'] = list(set(entry['pos']))\n",
    "      if len(entry['pos']) == 0: continue\n",
    "      training_set[key] = entry\n",
    "    return training_set\n",
    "\n",
    "parallel = get_parallel_data()\n",
    "len(parallel) # ESV_id to positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc0189c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31129/31129 [00:00<00:00, 109502.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3239"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch = {}\n",
    "from tqdm import tqdm\n",
    "for ESV_id, v_list in tqdm(parallel.items()): \n",
    "    found = {}\n",
    "    miss = []\n",
    "    for v in v_list['pos']: \n",
    "        v_id = v.split(\" (\")[0]\n",
    "        ver = v.split(\" (\")[-1].strip(\")\")\n",
    "        if ver in ['Douay-Rheims', 'Vulgate', 'Wycliffe','ODRV']: \n",
    "            v_id_std = fix_name_revert(v_id) \n",
    "        else: \n",
    "            v_id_std = v_id \n",
    "\n",
    "        if ESV_id not in mapping and v_id_std == ESV_id: \n",
    "            found[ver] = None \n",
    "            continue \n",
    "        elif ESV_id not in mapping and v_id_std != ESV_id: \n",
    "            miss.append((v_id,ver))\n",
    "        \n",
    "        elif ESV_id in mapping and ver in ['AKJV','Geneva','Tyndale']: \n",
    "            if v_id_std == ESV_id: \n",
    "                found[ver] = None \n",
    "            else: \n",
    "                miss.append((v_id, ver))\n",
    "        \n",
    "        elif ESV_id in mapping:\n",
    "            if v_id_std == mapping[ESV_id]: \n",
    "                found[ver] = None \n",
    "                continue \n",
    "            elif v_id == mapping[ESV_id]: \n",
    "                found[ver] = None \n",
    "                continue \n",
    "            else: \n",
    "                miss.append((v_id, ver))\n",
    "    for v_id,ver in miss: \n",
    "        if ver in found: continue \n",
    "        mismatch[(ESV_id, v_id)] = ver\n",
    "len(mismatch) # 1595 now 1496 (100 in the ones I looked at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81001a95",
   "metadata": {},
   "source": [
    "# Proper Nouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0dd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblical entities \n",
    "with open(f\"../assets/Bibles/TIPNR - Translators Individualised Proper Names with all References - STEPBible.org CC BY.txt\") as file: \n",
    "    data = file.readlines()\n",
    "in_entities_section = False\n",
    "e_to_v = {}\n",
    "for idx, line in enumerate(data): \n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    \n",
    "    if line.startswith('$========== '):\n",
    "        in_entities_section = True\n",
    "        continue  \n",
    "    \n",
    "    if idx < 112: continue\n",
    "    if idx > 14394: continue\n",
    "    if in_entities_section:\n",
    "        if line[0] != \"–\": continue \n",
    "        if not re.search(\"@\",line): continue \n",
    "        name = re.findall(\"^(.*?)@\",line)[0]\n",
    "        refs = line.split(\"reference=\")[-1].split(\"\\t\")[-1]\n",
    "        name = name.split(\"\\t\")[-1].split(\"|\")\n",
    "        KJV_name = re.findall(r\"KJV\\s*=\\s*(.*?)[);,]\",line)\n",
    "        if len(KJV_name) > 0: \n",
    "            KJV_name = KJV_name[0]\n",
    "            name.append(KJV_name)\n",
    "        for n in name: \n",
    "            n = re.sub(\"_\",\" \",n)\n",
    "            if n not in e_to_v: e_to_v[n] = []\n",
    "            ref_list = [re.findall(\"([\\d\\w]+)\\.(\\d+\\.\\d+)\",r) for r in refs.split(\"; \")]\n",
    "            ref_list = [f\"{corrected_books[r[0][0]]} {r[0][1]}\" for r in ref_list if len(r) > 0 if r[0][0] != 'Etc']\n",
    "            e_to_v[n].extend(sorted(list(set(ref_list))))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6022bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../assets/Bibles/proper_nouns.json\",'w+') as file: \n",
    "    json.dump(e_to_v, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a284a1",
   "metadata": {},
   "source": [
    "# Citations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae92a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/76 [00:16<07:02,  5.79s/it]/var/folders/3_/ylrg8wdj20l755p4921q0wg80000gp/T/ipykernel_11556/2553457035.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  text = pd.read_csv(f\"../../SERMONS_APP/db/data/{era}/{prefix}_body.csv\",header=None).to_dict(orient='records')\n",
      " 36%|███▌      | 27/76 [01:40<01:25,  1.75s/it]/var/folders/3_/ylrg8wdj20l755p4921q0wg80000gp/T/ipykernel_11556/2553457035.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  text = pd.read_csv(f\"../../SERMONS_APP/db/data/{era}/{prefix}_body.csv\",header=None).to_dict(orient='records')\n",
      " 84%|████████▍ | 64/76 [03:23<00:39,  3.29s/it]/var/folders/3_/ylrg8wdj20l755p4921q0wg80000gp/T/ipykernel_11556/2553457035.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  text = pd.read_csv(f\"../../SERMONS_APP/db/data/{era}/{prefix}_body.csv\",header=None).to_dict(orient='records')\n",
      "100%|██████████| 76/76 [03:43<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  \n",
    "def clean_text(s): \n",
    "    s = re.sub(r\"\\<\\/i\\>|\\<NOTE\\>|NONLATINALPHABET|\\<i\\>|\\d+\\^PAGE[S]*\\^MISSING\",\"\",s)\n",
    "    s = re.sub(r\"\\s+\",\" \",s)\n",
    "    s = s.strip(\" \")\n",
    "    return s \n",
    "all_c = {}\n",
    "c_repo = \"../../CITATIONS\"\n",
    "c_files = sorted(k for k in os.listdir(c_repo) if \".csv\" in k)\n",
    "for file in tqdm(c_files): \n",
    "    era, prefix = file.split(\"_citations.csv\")[0].split(\"_\")\n",
    "    # print(era,prefix)\n",
    "    data = pd.read_csv(f\"{c_repo}/{file}\",header=None).to_dict(orient='records')\n",
    "    data = {(d[0],d[1],d[2]):d for d in data}\n",
    "    text = pd.read_csv(f\"../../SERMONS_APP/db/data/{era}/{prefix}_body.csv\",header=None).to_dict(orient='records')\n",
    "    text = {(d[0],d[1],\"In-Text\"):clean_text(d[6]) for d in text}\n",
    "    for key, t in text.items(): \n",
    "        if key in data: \n",
    "            data[key]['text'] = t \n",
    "    if f\"{prefix}_margin.csv\" in os.listdir(f\"../../SERMONS_APP/db/data/{era}\"): \n",
    "        text = pd.read_csv(f\"../../SERMONS_APP/db/data/{era}/{prefix}_margin.csv\",header=None).to_dict(orient='records')\n",
    "        text = {(d[0],d[1],\"Note \" + str(d[2])):clean_text(d[3]) for d in text}\n",
    "        for key, t in text.items(): \n",
    "            if key in data: \n",
    "                data[key]['text'] = t\n",
    "    for d in data.values(): \n",
    "        all_c[d[6]] = d[4] \n",
    "    # data = pd.DataFrame(list(data.values()))\n",
    "    # data.to_csv(f\"{c_repo}/{file}\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240ed15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hosea 11. 11.', 'Hosea 11.11'),\n",
       " ('Zek. 16.', 'Ezekiel 16'),\n",
       " ('Cant. 5.', 'Canticles 5'),\n",
       " ('Psalms 18.', 'Psalms 18'),\n",
       " ('Psalms 91.', 'Psalms 91'),\n",
       " ('John 15. 4:', 'John 15.4'),\n",
       " ('Psalms 18. 2.', 'Psalms 18.2'),\n",
       " ('Heb. 1.', 'Hebrews 1'),\n",
       " ('Isaiah 56.', 'Isaiah 56')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_c.items())[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3335a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "from lib.EEPS_helper import isNumeral\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02df1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306017/306017 [00:13<00:00, 21964.18it/s]\n"
     ]
    }
   ],
   "source": [
    "formats = {}\n",
    "\n",
    "def space_punctuation(text):\n",
    "    text = re.sub(r'([\\.\\,\\:\\;\\!\\?\\(\\)\\-\\&])(?=\\w)', r'\\1 ', text)\n",
    "    text = re.sub(r'(?<=\\w)([\\.\\,\\:\\;\\!\\?\\(\\)\\-\\&])', r' \\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "for orig in tqdm(all_c): \n",
    "    if orig == '6': continue \n",
    "    text = space_punctuation(orig)\n",
    "    tokens = text.split(\" \")\n",
    "    format = []\n",
    "    for t in tokens: \n",
    "        if isNumeral(t): \n",
    "            format.append('N')\n",
    "        elif re.search(r\"[\\.\\,\\:\\;\\!\\?\\(\\)\\-\\&]\",t):  \n",
    "            format.append(t)\n",
    "        else: \n",
    "            format.append('W')\n",
    "    format = \" \".join(format)\n",
    "    if format not in formats: formats[format] = 0\n",
    "    formats[format] += 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da430f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('W . N . N .', 77457),\n",
       " ('W N . N .', 26984),\n",
       " ('W . N . N , N .', 15415),\n",
       " ('W . N . N', 13070),\n",
       " ('W . N . N . N .', 12395),\n",
       " ('N W . N . N .', 11083),\n",
       " ('W . N .', 8721),\n",
       " ('N . W . N . N .', 6718),\n",
       " ('W . N N .', 4893),\n",
       " ('W . N . N .)', 4872)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(formats).most_common(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97b0e5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'canticles': 'cant',\n",
       " 'hosea': 'hos',\n",
       " 'ezekiel': 'ezek',\n",
       " 'psalms': 'psal',\n",
       " 'john': 'john',\n",
       " 'hebrews': 'heb',\n",
       " 'isaiah': 'isa',\n",
       " 'romans': 'rom',\n",
       " 'philippians': 'phil',\n",
       " 'corinthians': 'cor',\n",
       " 'matthew': 'mat',\n",
       " 'jeremiah': 'jer',\n",
       " 'proverbs': 'prov',\n",
       " 'acts': 'acts',\n",
       " 'kings': 'king',\n",
       " 'verse': 'ver',\n",
       " 'revelation': 'rev',\n",
       " 'luke': 'luke',\n",
       " 'chronicles': 'chron',\n",
       " 'timothy': 'tim',\n",
       " 'james': 'jam',\n",
       " 'peter': 'pet',\n",
       " 'titus': 'tit',\n",
       " 'jude': 'iud',\n",
       " 'ephesians': 'eph',\n",
       " 'colossians': 'col',\n",
       " 'galatians': 'gal',\n",
       " 'deuteronomy': 'deut',\n",
       " 'samuel': 'sam',\n",
       " 'job': 'job',\n",
       " 'genesis': 'gen',\n",
       " 'micah': 'micah',\n",
       " 'lamentations': 'lam',\n",
       " 'leviticus': 'levit',\n",
       " 'exodus': 'exod',\n",
       " 'zephaniah': 'zeph',\n",
       " 'wisdom': 'wisd',\n",
       " 'daniel': 'dan',\n",
       " 'judges': 'judg',\n",
       " 'joshua': 'josh',\n",
       " 'mark': 'mark',\n",
       " 'habakkuk': 'hab',\n",
       " 'thessalonians': 'thes',\n",
       " 'esther': 'es',\n",
       " 'ecclesiastes': 'eccles',\n",
       " 'zechariah': 'zach',\n",
       " 'ezra': 'ezra',\n",
       " 'amos': 'amos',\n",
       " 'malachi': 'mal',\n",
       " 'numbers': 'numb',\n",
       " 'haggai': 'hag',\n",
       " 'jonah': 'ionah',\n",
       " 'joel': 'ioel',\n",
       " 'nehemiah': 'neh',\n",
       " 'epistle': 'epist',\n",
       " 'manasseh': 'manasseh',\n",
       " 'ruth': 'ruth',\n",
       " 'obadiah': 'obad',\n",
       " 'philemon': 'philem',\n",
       " 'nahum': 'nahum',\n",
       " 'baruch': 'baruch',\n",
       " 'ibidem': 'ibid',\n",
       " 'ecclesiasticus': 'ecclus',\n",
       " 'maccabees': 'maccab',\n",
       " 'judith': 'iudith',\n",
       " 'tobit': 'tob',\n",
       " 'azariah': 'azariah',\n",
       " 'esdras': 'esd',\n",
       " 'susanna': 'susanna'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_books = {}\n",
    "for orig, std in all_c.items(): \n",
    "    if orig == '6' and std == '4': continue \n",
    "    words = re.findall(r\"([A-Za-z]+)\",orig)\n",
    "    book = re.findall(r\"[A-Za-z]+\",std)[0].lower()\n",
    "    if book not in all_books: \n",
    "        all_books[book] = {}\n",
    "    for w in words: \n",
    "        if isNumeral(w): \n",
    "            continue \n",
    "        w = w.lower()\n",
    "        if w in ['of','cap','chap','verse','vers','chapter','ch']:\n",
    "            continue \n",
    "        if w not in all_books[book]: \n",
    "            all_books[book][w] = 0 \n",
    "        all_books[book][w] += 1 \n",
    "\n",
    "common_abbrev = {}\n",
    "for book, abbrevs in all_books.items(): \n",
    "    if book == \"children\": continue \n",
    "    top = Counter(abbrevs).most_common(n=1)[0]\n",
    "    common_abbrev[book] = top[0] \n",
    "\n",
    "with open(f\"../assets/Bibles/top_abbrev.json\",'w+') as file: \n",
    "    json.dump(common_abbrev, file)\n",
    "common_abbrev "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sermons_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
