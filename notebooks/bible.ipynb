{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,re\n",
    "sys.path.append('../')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_book = {\"KJV\":\n",
    "                        {\"Wisdom-of-Solomon\":\"Wisdom\",\"Prayer-of-Azariah\":\"Azariah\",\n",
    "                        \"Song-of-Solomon\":\"Canticles\",\"Epistle-of-Jeremiah\":\"Jeremiah\",\n",
    "                        \"Prayer-of-Manasseh\":\"Manasseh\",\"Acts-of-the-Apostles\":\"Acts\"},\n",
    "                \"Douay-Rheims\": \n",
    "                        {\"Psalm\":\"Psalms\",\"Song-of-Solomon\":\"Canticles\"},\n",
    "                \"LV\": {'Gen': \"Genesis\", 'Exo': \"Exodus\", 'Lev': \"Leviticus\", \n",
    "                        'Num': \"Numbers\", 'Deu': \"Deuteronomy\", 'Jos': \"Joshua\", \n",
    "                        'Jdg': \"Judges\", 'Rut': \"Ruth\", 'Sa1': \"1 Samuel\", \n",
    "                        'Sa2': \"2 Samuel\", 'Kg1': \"1 Kings\", 'Kg2': \"2 Kings\", \n",
    "                        'Ch1': \"1 Chronicles\", 'Ch2': \"2 Chronicles\", 'Ezr': \"Ezra\", \n",
    "                        'Neh': \"Nehemiah\", 'Tob': \"Tobit\", 'Jdt': \"Judith\", \n",
    "                        'Est': \"Esther\", 'Job': \"Job\", 'Psa': \"Psalms\", \n",
    "                        'Pro': \"Proverbs\", 'Ecc': \"Ecclesiastes\", 'Sol': \"Canticles\", \n",
    "                        'Wis': \"Wisdom\", 'Sir': \"Ecclesiasticus\", 'Isa': \"Isaiah\", \n",
    "                        'Jer': \"Jeremiah\", 'Lam': \"Lamentations\", 'Bar': \"Baruch\", \n",
    "                        'Eze': \"Ezekiel\", 'Dan': \"Daniel\", 'Hos': \"Hosea\", \n",
    "                        'Joe': \"Joel\", 'Amo': \"Amos\", 'Oba': \"Obadiah\", \n",
    "                        'Jon': \"Jonah\", 'Mic': \"Micah\", 'Nah': \"Nahum\", \n",
    "                        'Hab': \"Habakkuk\", 'Zep': \"Zephaniah\", 'Hag': \"Haggai\", \n",
    "                        'Zac': \"Zechariah\", 'Mal': \"Malachi\", 'Ma1': \"1 Maccabees\", \n",
    "                        'Ma2': \"2 Maccabees\", 'Mat': \"Matthew\", 'Mar': \"Mark\", \n",
    "                        'Luk': \"Luke\", 'Joh': \"John\", 'Act': \"Acts\", \n",
    "                        'Rom': \"Romans\", 'Co1': \"1 Corinthians\", 'Co2': \"2 Corinthians\", \n",
    "                        'Gal': \"Galatians\", 'Eph': \"Ephesians\", 'Phi': \"Philippians\", \n",
    "                        'Col': \"Colossians\", 'Th1': \"1 Thessalonians\", 'Th2': \"2 Thessalonians\", \n",
    "                        'Ti1': \"1 Timothy\", 'Ti2': \"2 Timothy\", 'Tit': \"Titus\", \n",
    "                        'Plm': \"Philemon\", 'Heb': \"Hebrews\", 'Jam': \"James\", \n",
    "                        'Pe1': \"1 Peter\", 'Pe2': \"2 Peter\", 'Jo1': \"1 John\", \n",
    "                        'Jo2': \"2 John\", 'Jo3': \"3 John\", 'Jde': \"Jude\", \n",
    "                        'Rev': \"Revelation\"}\n",
    "                }\n",
    "\n",
    "def read_bible(ver):\n",
    "    bible = pd.read_csv(f'../assets/bible/{ver}.csv')\n",
    "    bible_dict = {}\n",
    "    bible_books = {}\n",
    "    for idx,verse_id in enumerate(bible['doc_id']): \n",
    "        verse_id = verse_id.split(\"(KJV)\")[0].strip(\" \")\n",
    "        verse_id = re.sub(r\"[\\s\\:]\",\"-\",verse_id)\n",
    "        book = bible['book'][idx]\n",
    "        if \"-\".join(book.split(\" \")) in convert_book[ver]: \n",
    "            verse_id = re.sub(book,convert_book[ver][\"-\".join(book.split(\" \"))],verse_id)\n",
    "            book = convert_book[ver][\"-\".join(book.split(\" \"))]\n",
    "        bible_dict[verse_id] = bible['text'][idx]\n",
    "        bible_books[book] = bible['part'][idx]\n",
    "    return bible_dict, bible_books\n",
    "\n",
    "\n",
    "kjv, kjv_books = read_bible(\"KJV\")\n",
    "drv, drv_books = read_bible(\"Douay-Rheims\")\n",
    "\n",
    "\n",
    "def read_vulgate(): \n",
    "    with open(\"../assets/bible/vuldat.txt\") as file: \n",
    "        bible = file.readlines()\n",
    "    bible_dict = {}\n",
    "    bible_books = {}\n",
    "    new = []\n",
    "    for b in bible: \n",
    "        b = b.strip(\"\\n\")\n",
    "        book,chapter,verse,text = b.split(\"|\")\n",
    "        if book in convert_book[\"LV\"]: \n",
    "            book = convert_book[\"LV\"][book]\n",
    "        chap_ver = \".\".join([chapter,verse])\n",
    "        version = \"Latin Vulgate\"\n",
    "        verse_id = f\"{book} {chap_ver} ({version})\"\n",
    "        bible_dict[verse_id] = text \n",
    "        bible_books[book] = kjv_books[book] # drv_books[book] \n",
    "        \n",
    "        new.append({0:verse_id, \n",
    "                1:version,\n",
    "                2:kjv_books[book],\n",
    "                3:book,\n",
    "                4:chapter,\n",
    "                5:verse,\n",
    "                6:text})\n",
    "    with open(f\"{outputfolder}/LV.csv\",\"w+\") as outfile: \n",
    "        writer = csv.DictWriter(outfile, fieldnames=new[0].keys())\n",
    "        writer.writerows(new)\n",
    "    return bible_dict, bible_books\n",
    "\n",
    "lv, lv_books = read_vulgate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "outputfolder = \"/Users/amycweng/DH/SERMONS_APP/db/data\"\n",
    "new = []\n",
    "bible = {}\n",
    "ver = \"LV\"\n",
    "# doc_id,version,part,book,chapter,verse,text\n",
    "with open(\"../assets/bible/vuldat.txt\") as file: \n",
    "    bible = file.readlines()\n",
    "bible_dict = {}\n",
    "bible_books = {}\n",
    "for b in bible: \n",
    "    book,chapter,verse,text = b.split(\"|\")\n",
    "    if book in convert_book[\"LV\"]: \n",
    "        book = convert_book[\"LV\"][book]\n",
    "        book = \"-\".join(book.split(\" \"))\n",
    "    verse_id = \"-\".join([book,chapter,verse])\n",
    "    bible_dict[verse_id] = text \n",
    "\n",
    "for idx,verse_id in enumerate(biblecsv['doc_id']): \n",
    "    orig_id = verse_id\n",
    "    book = \"-\".join(biblecsv['book'][idx].split(\" \"))\n",
    "    if book in convert_book[ver]: \n",
    "        new_book = re.sub(\"-\",\" \",convert_book[ver][book])\n",
    "        verse_id = re.sub(biblecsv['book'][idx],new_book,verse_id)\n",
    "        book = convert_book[ver][book]\n",
    "    verse_id = re.sub(r\"[\\:]\",\".\",verse_id)\n",
    "    bible[verse_id] = biblecsv['text'][idx]\n",
    "    new.append({0:verse_id, \n",
    "                1:biblecsv['version'][idx],\n",
    "                2:biblecsv['part'][idx],\n",
    "                3:book,\n",
    "                4:biblecsv['chapter'][idx],\n",
    "                5:biblecsv['verse'][idx],\n",
    "                6:biblecsv['text'][idx]})\n",
    "with open(f\"{outputfolder}/{ver}.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=new[0].keys())\n",
    "    writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "outputfolder = \"/Users/amycweng/DH/SERMONS_APP/db/data\"\n",
    "new = []\n",
    "bible = {}\n",
    "ver = \"Douay-Rheims\"\n",
    "# doc_id,version,part,book,chapter,verse,text\n",
    "biblecsv = pd.read_csv(f'../assets/bible/{ver}.csv')\n",
    "for idx,verse_id in enumerate(biblecsv['doc_id']): \n",
    "    orig_id = verse_id\n",
    "    book = \"-\".join(biblecsv['book'][idx].split(\" \"))\n",
    "    if book in convert_book[ver]: \n",
    "        new_book = re.sub(\"-\",\" \",convert_book[ver][book])\n",
    "        verse_id = re.sub(biblecsv['book'][idx],new_book,verse_id)\n",
    "        book = convert_book[ver][book]\n",
    "    verse_id = re.sub(r\"[\\:]\",\".\",verse_id)\n",
    "    bible[verse_id] = biblecsv['text'][idx]\n",
    "    new.append({0:verse_id, \n",
    "                1:biblecsv['version'][idx],\n",
    "                2:biblecsv['part'][idx],\n",
    "                3:book,\n",
    "                4:biblecsv['chapter'][idx],\n",
    "                5:biblecsv['verse'][idx],\n",
    "                6:biblecsv['text'][idx]})\n",
    "with open(f\"{outputfolder}/{ver}.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=new[0].keys())\n",
    "    writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_verse(segment):\n",
    "    pattern = r'\\s+([,.?!;:)])'\n",
    "    segment = re.sub(pattern, r'\\1', segment)\n",
    "    pattern = r'([(])\\s+'\n",
    "    segment = re.sub(pattern, r'\\1', segment)\n",
    "    \n",
    "    if len(segment.split(\" \")) < 32: # below 75th percentile  \n",
    "        return [segment]\n",
    "    subsegments = re.split(r\"\\.|\\;|\\?|\\!\",segment)\n",
    "    # to_segment = [\"but\", \", while\", \", let\", \", they\", \", NONLATINALPHABET\",\n",
    "    #                 \", then\", \", yet\", \", than\", ', and yet', ', and though',\n",
    "    #                 ', at least', ', and to', ', this be', ', for', ', therefore',\n",
    "    #                 ', that', ', and we', ', and i ', ', when', ', and say', ', and this',\n",
    "    #                 ', and then', ', and than', ', and they', ', i say', ', as the apostle',\n",
    "    #                 ', otherwise', ', how', ', according', ', accordi^^', ', say',', and when',\n",
    "    #                 ', and he', ', and she', ', he say', ', she say', ', lest', ', and where',\n",
    "    #                 ', and how', ', and what', ', and there', ', and therefore', ', and thus',\n",
    "    #                 ', and if', ', and because', ', and I ', ', he will', ', they will', ', she will']\n",
    "    # pattern = '|'.join(map(re.escape, to_segment))\n",
    "    # all_parts = []\n",
    "    # for segment in subsegments: \n",
    "    #     parts = re.split(pattern, segment)\n",
    "    #     matches = re.findall(pattern,segment)\n",
    "    #     for idx, part in enumerate(parts):\n",
    "    #         if idx == (len(parts) - 1): break\n",
    "    #         # if len(part) == 0: continue\n",
    "    #         conj = re.sub(\", \", \"\",matches[idx])\n",
    "    #         parts[idx] = part\n",
    "    #         parts[idx + 1] = conj + parts[idx+1]\n",
    "    #     all_parts.extend(parts)\n",
    "    return_parts = []\n",
    "    merge = False \n",
    "    for part in subsegments:\n",
    "        part = part.strip(\" \")\n",
    "        # if len(part) > 1 and not re.search(r\"^\\)\\s*$|^\\(\\s*$|^[bB]ehold[\\s\\,]*$|^say[\\s\\,]*|^and say[\\s\\,]*|^and you$\",part): \n",
    "        if re.search(r\"say|saith\",part): \n",
    "            # merge with prior part\n",
    "            if len(return_parts) == 0: \n",
    "                merge = True\n",
    "                return_parts.append(part)\n",
    "            else: \n",
    "                return_parts[-1] = return_parts[-1] + \" \" + part  \n",
    "        else: \n",
    "            if merge: \n",
    "                merge = False \n",
    "                return_parts[-1] = return_parts[-1] + \" \" + part\n",
    "            else: \n",
    "                return_parts.append(part) \n",
    "    return return_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_bible = {}\n",
    "for label, verse in bible.items(): \n",
    "    segmented_bible[label] = split_verse(verse)\n",
    "bible_labels = []\n",
    "bible_parts = [] \n",
    "for label, verse in segmented_bible.items(): \n",
    "    for part in verse:\n",
    "        if len(part.split(\" \")) < 2: continue\n",
    "        bible_parts.append(part)\n",
    "        bible_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.0, 21.0, 28.0, 52.0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(s.split(\" \")) for s in bible_parts]\n",
    "import numpy as np \n",
    "np.percentile(lengths,25),np.percentile(lengths,50),np.percentile(lengths,75),np.percentile(lengths,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(norm=None, analyzer='word',sublinear_tf=True)\n",
    "tfidf_bible = vector.fit_transform(bible_parts)\n",
    "df = pd.DataFrame(tfidf_bible.toarray(), columns = vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average TFIDF score for each verse \n",
    "for idx, score in enumerate(doc_scores): \n",
    "    num_words = len(bible_parts[idx].split(\" \"))\n",
    "    doc_scores[idx] = score/num_words\n",
    "sorted_docs = np.argsort(doc_scores)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/bible/bible_parts.txt','w') as file: \n",
    "    for idx in sorted_docs: \n",
    "        file.write(bible_labels[idx]+\"\\n\")\n",
    "        file.write(bible_parts[idx]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "bible = {}\n",
    "outputfolder = \"/Users/amycweng/DH/SERMONS_APP/db/data\"\n",
    "with open(f'../assets/bible/bible_parts.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "    for idx, line in enumerate(lines):\n",
    "      if len(re.findall(\"-\",line)) >= 2 and not re.search(\" \", line.strip(\"\\n\")):\n",
    "        verse = line.strip(\"\\n\")\n",
    "        text = lines[idx+1].strip(\"\\n\").strip(\" \")\n",
    "        # if re.search(r\"^or else$|^yea$|^moreover$|^[lL]o$|^if otherwise$|^wait$|^and yet true$\",text): continue\n",
    "        if verse not in bible: bible[verse] = []\n",
    "        bible[verse].append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36716"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for p_list in bible.values(): \n",
    "    unique.extend(p_list)\n",
    "unique = {phrase:idx for idx, phrase in enumerate(set(unique))}\n",
    "unique_bible = {idx:[] for idx in unique.values()}\n",
    "for label, v_list in bible.items():\n",
    "    for verse in v_list:\n",
    "        vidx = unique[verse]\n",
    "        unique_bible[vidx].append(label)\n",
    "phrases_csv = []\n",
    "for phrase, vidx in unique.items(): \n",
    "    phrases_csv.append({\"vidx\":vidx, \"phrase\":phrase})\n",
    "\n",
    "bible_vindices = []\n",
    "for label, vlist in bible.items(): \n",
    "    seen = []\n",
    "    label = re.sub(\"-\",\" \",label).split(\" \")\n",
    "    label = \" \".join(label[:-2]) + \" \" + label[-2] + \":\" + label[-1] + \" (KJV)\"\n",
    "    for v in vlist: \n",
    "        vidx = unique[v]\n",
    "        if vidx in seen: continue\n",
    "        bible_vindices.append({'vidx':vidx, 'verse_id':label})\n",
    "        seen.append(vidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{outputfolder}/bible_phrase_indices.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=bible_vindices[0].keys())\n",
    "    writer.writerows(bible_vindices)\n",
    "with open(f\"{outputfolder}/bible_phrases.csv\",\"w+\") as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=phrases_csv[0].keys())\n",
    "    writer.writerows(phrases_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
