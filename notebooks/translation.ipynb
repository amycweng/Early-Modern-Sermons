{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 known translations\n"
     ]
    }
   ],
   "source": [
    "import json,re \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "all_translations = {}\n",
    "for fp in os.listdir('../assets/translations'):\n",
    "    with open(f\"../assets/translations/{fp}\") as file: \n",
    "        all_translations.update(json.load(file))\n",
    "print(len(all_translations),\"known translations\")\n",
    "\n",
    "def combine_punc_with_text(segment): \n",
    "    segment = re.sub(r'\\s+([,.?!;:)])', r'\\1', segment)\n",
    "    segment = re.sub(r'([(])\\s+', r'\\1', segment) \n",
    "    segment = re.sub(r\"\\s+\",\" \",segment)\n",
    "    return segment\n",
    "\n",
    "def get_foreign(era,prefix,get=\"missing\"): \n",
    "    with open(f\"../assets/processed/{era}/sub-segments/{prefix}.json\",'r') as file:\n",
    "        s_ids, standardized, fw_subchunks = json.load(file)\n",
    "\n",
    "    parts = {}\n",
    "    for idx, s in enumerate(standardized):\n",
    "        s_id = s_ids[idx]\n",
    "        new_id = [str(s) for s in s_id[0]]\n",
    "        new_id = [new_id,str(s_id[1])]\n",
    "        parts[str(new_id)] = combine_punc_with_text(s)\n",
    "\n",
    "    fstrings = {}\n",
    "    foreign = []\n",
    "    for fid in fw_subchunks:\n",
    "        if parts[fid] not in fstrings:\n",
    "            fstrings[parts[fid]] = None \n",
    "            if get == \"missing\":\n",
    "                if parts[fid] not in all_translations: \n",
    "                    foreign.append((fid,parts[fid]))\n",
    "            else: \n",
    "                foreign.append((fid,parts[fid]))\n",
    "    print(len(foreign),\"sentences to translate\")\n",
    "    return parts, foreign,fw_subchunks\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "env_path = '../../DH/openai.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "OPENAI_API_KEY = os.getenv('SECRET_KEY')\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def translate(sentences):\n",
    "    sentences = [f\"{fid}: {s}\" for fid, s in sentences if s not in all_translations]\n",
    "    if len(sentences) == 0: return None \n",
    "    # Prepare the system message\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an assistant that translates Latin text from Early Modern English sermons. The input sentences are separated by newlines and preceded by their unique four-part id (containing underscores). Only output the translation of the Latin and ignore the English. Be as continuous as possible and precede the translation with its corresponding id. Do not repeat my input.\"\n",
    "    }\n",
    "\n",
    "    # Prepare the user message with the list of words\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Translate to English if most of the sentence is in Latin: \" + \"\\n\".join(sentences)\n",
    "    }\n",
    "\n",
    "    # Call the OpenAI API with the messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[system_message, user_message]\n",
    "    )\n",
    "\n",
    "    # Extract the result from the response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start, end = 0,21 # preE B: 0:20, 20:50\n",
    "translations = translate(foreign[start:end])\n",
    "translations = translations.choices[0].message.content\n",
    "for t in translations.split(\"\\n\"): \n",
    "    if \":\" not in t: continue\n",
    "    fid = t.split(\":\")[0].split(\"_\")\n",
    "    sid = fid[:3]\n",
    "    sid[1],sid[2] = int(sid[1]), int(sid[2])\n",
    "    pid = int(fid[-1])\n",
    "    all_translations[parts[str([sid,pid])]] = t.split(\":\")[1]\n",
    "    print(parts[str([sid,pid])],f\"\\n\\t{t.split(':')[1]}\\n\")\n",
    "with open(f\"../assets/translations/{era}_{prefix}.json\",\"w+\") as file: \n",
    "    json.dump(all_translations,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-Elizabethan B\n",
      "300 sentences to translate\n",
      "pre-Elizabethan A0\n",
      "1874 sentences to translate\n",
      "pre-Elizabethan A1\n",
      "716 sentences to translate\n",
      "pre-Elizabethan A2\n",
      "1391 sentences to translate\n",
      "pre-Elizabethan A6\n",
      "70 sentences to translate\n",
      "pre-Elizabethan A7\n",
      "46 sentences to translate\n",
      "Elizabethan B\n",
      "626 sentences to translate\n",
      "Elizabethan A0\n",
      "5059 sentences to translate\n",
      "Elizabethan A1\n",
      "3994 sentences to translate\n",
      "Elizabethan A2\n",
      "283 sentences to translate\n",
      "Elizabethan A6\n",
      "9404 sentences to translate\n",
      "Elizabethan A7\n",
      "106 sentences to translate\n",
      "Jacobean B\n",
      "1595 sentences to translate\n",
      "Jacobean A0\n",
      "16775 sentences to translate\n",
      "Jacobean A1\n",
      "9412 sentences to translate\n",
      "Jacobean A2\n",
      "1412 sentences to translate\n",
      "Jacobean A6\n",
      "758 sentences to translate\n",
      "Jacobean A7\n",
      "833 sentences to translate\n",
      "Jacobean A8\n",
      "6 sentences to translate\n",
      "Carolinian B\n",
      "3040 sentences to translate\n",
      "Carolinian A0\n",
      "15010 sentences to translate\n",
      "Carolinian A1\n",
      "13247 sentences to translate\n",
      "Carolinian A2\n",
      "2392 sentences to translate\n",
      "Carolinian A3\n",
      "92 sentences to translate\n",
      "Carolinian A4\n",
      "99 sentences to translate\n",
      "Carolinian A5\n",
      "299 sentences to translate\n",
      "Carolinian A6\n",
      "3567 sentences to translate\n",
      "Carolinian A7\n",
      "5091 sentences to translate\n",
      "Carolinian A8\n",
      "66 sentences to translate\n",
      "Carolinian A9\n",
      "167 sentences to translate\n",
      "CivilWar B\n",
      "280 sentences to translate\n",
      "CivilWar A2\n",
      "902 sentences to translate\n",
      "CivilWar A3\n",
      "1755 sentences to translate\n",
      "CivilWar A4\n",
      "2011 sentences to translate\n",
      "CivilWar A5\n",
      "1461 sentences to translate\n",
      "CivilWar A6\n",
      "1712 sentences to translate\n",
      "CivilWar A7\n",
      "1772 sentences to translate\n",
      "CivilWar A8\n",
      "2077 sentences to translate\n",
      "CivilWar A9\n",
      "3380 sentences to translate\n",
      "Interregnum B\n",
      "198 sentences to translate\n",
      "Interregnum A2\n",
      "2574 sentences to translate\n",
      "Interregnum A3\n",
      "3524 sentences to translate\n",
      "Interregnum A4\n",
      "3926 sentences to translate\n",
      "Interregnum A5\n",
      "2419 sentences to translate\n",
      "Interregnum A6\n",
      "3249 sentences to translate\n",
      "Interregnum A7\n",
      "1592 sentences to translate\n",
      "Interregnum A8\n",
      "5389 sentences to translate\n",
      "Interregnum A9\n",
      "2958 sentences to translate\n",
      "CharlesII B\n",
      "1439 sentences to translate\n",
      "CharlesII A1\n",
      "0 sentences to translate\n",
      "CharlesII A2\n",
      "4167 sentences to translate\n",
      "CharlesII A3\n",
      "7215 sentences to translate\n",
      "CharlesII A4\n",
      "13818 sentences to translate\n",
      "CharlesII A5\n",
      "5798 sentences to translate\n",
      "CharlesII A6\n",
      "6009 sentences to translate\n",
      "CharlesII A7\n",
      "5217 sentences to translate\n",
      "CharlesII A8\n",
      "1973 sentences to translate\n",
      "CharlesII A9\n",
      "2243 sentences to translate\n",
      "JamesII B\n",
      "542 sentences to translate\n",
      "JamesII A2\n",
      "324 sentences to translate\n",
      "JamesII A3\n",
      "1287 sentences to translate\n",
      "JamesII A4\n",
      "654 sentences to translate\n",
      "JamesII A5\n",
      "442 sentences to translate\n",
      "JamesII A6\n",
      "1488 sentences to translate\n",
      "JamesII A7\n",
      "83 sentences to translate\n",
      "JamesII A8\n",
      "36 sentences to translate\n",
      "JamesII A9\n",
      "38 sentences to translate\n",
      "WilliamAndMary B\n",
      "297 sentences to translate\n",
      "WilliamAndMary A0\n",
      "0 sentences to translate\n",
      "WilliamAndMary A2\n",
      "452 sentences to translate\n",
      "WilliamAndMary A3\n",
      "851 sentences to translate\n",
      "WilliamAndMary A4\n",
      "841 sentences to translate\n",
      "WilliamAndMary A5\n",
      "1205 sentences to translate\n",
      "WilliamAndMary A6\n",
      "1643 sentences to translate\n",
      "WilliamAndMary A7\n",
      "99 sentences to translate\n",
      "WilliamAndMary A8\n",
      "48 sentences to translate\n",
      "WilliamAndMary A9\n",
      "33 sentences to translate\n"
     ]
    }
   ],
   "source": [
    "parts,foreign,fw_subchunks= {},[],{}\n",
    "\n",
    "with open('../assets/corpora.json','r') as file: \n",
    "    corpora = json.load(file)\n",
    "\n",
    "for era in corpora: \n",
    "    for prefix,id_list in corpora[era].items():\n",
    "        if len(id_list) == 0: continue\n",
    "        print(era,prefix)\n",
    "        p,f,fw = get_foreign(era,prefix,'All')\n",
    "        parts.update(p)\n",
    "        foreign.extend(f)\n",
    "        fw_subchunks.update(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149530 sub-segments to translate\n",
      "83.20904835150137 average sub-segment length\n",
      "5-th percentile of foreign phrase length: 0.38461538461538464\n",
      "10-th percentile of foreign phrase length: 0.47058823529411764\n",
      "25-th percentile of foreign phrase length: 0.6363636363636364\n",
      "30-th percentile of foreign phrase length: 0.6666666666666666\n",
      "40-th percentile of foreign phrase length: 0.75\n",
      "50-th percentile of foreign phrase length: 0.782608695652174\n",
      "75-th percentile of foreign phrase length: 0.8888888888888888\n",
      "90-th percentile of foreign phrase length: 1.0\n",
      "99-th percentile of foreign phrase length: 1.0\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "condensed = []\n",
    "for fid,fw in fw_subchunks.items():\n",
    "    if len(fw)/len(parts[fid].split(\" \")) > 0.32: # 25th percentile \n",
    "    # if parts[fid] in all_translations: \n",
    "        # print(parts[fid])\n",
    "        # print(parts[fid])\n",
    "        condensed.append(len(parts[fid]))\n",
    "        counts.append(len(fw)/len(parts[fid].split(\" \")))\n",
    "import numpy as np \n",
    "print(len(condensed),\"sub-segments to translate\")\n",
    "print(np.mean(condensed),\"average sub-segment length\")\n",
    "percents = [5,10,25,30,40,50,75,90,99]\n",
    "for p in percents: \n",
    "    print(f\"{p}-th percentile of foreign phrase length: {np.percentile(counts,p)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
