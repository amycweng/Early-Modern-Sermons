{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import json,math,sys,re\n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "qp_folder = \"/Users/amycweng/Downloads/QP\"\n",
    "\n",
    "bible_info = {}\n",
    "for bname in ['Geneva', 'Vulgate', 'Douay-Rheims', 'Tyndale', 'Wycliffe', 'KJV']:\n",
    "    data = pd.read_csv(f\"../assets/Bibles/{bname}.csv\",header=None) \n",
    "    data = data.to_dict(orient=\"records\")\n",
    "    for entry in data: \n",
    "       bible_info[entry[0]] = (entry[1], entry[2], entry[3]) # version, part, book\n",
    "\n",
    "def get_bible_info(id_string): \n",
    "    ids = re.findall(r\"\\'(.*?)\\'\", id_string)\n",
    "    if len(ids) == 0: \n",
    "        ids = [id_string]\n",
    "    ids = [id.split(\" -\")[0] for id in ids]\n",
    "    id = ids[0] .strip()\n",
    "    id = re.sub(\" Bible\",\"\",id)\n",
    "    version, part, book = bible_info[id]\n",
    "    return version, part, book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615, 4842)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data_and_labels(inputfname): \n",
    "    data = pd.read_csv(f\"{qp_folder}/{inputfname}.csv\")\n",
    "    if 'preE_qp' == inputfname: \n",
    "        data = data.drop(columns=['0','1','2','4','5','Unnamed: 7'])\n",
    "        data = data.rename(columns = {'3': 'verse_id','6':'text','8':'verse_text','9':'label'})\n",
    "    with open(f\"/Users/amycweng/DH/Early-Modern-Sermons/assets/QP_labels/{inputfname}_DS.json\",'r') as f: \n",
    "        labels_DS = json.load(f) \n",
    "    with open(f\"/Users/amycweng/DH/Early-Modern-Sermons/assets/QP_labels/{inputfname}_GPT.json\",'r') as f: \n",
    "        labels_GPT = json.load(f) \n",
    "    return data, labels_DS, labels_GPT\n",
    "\n",
    "VnotPinC,VnotPinC_DS,VnotPinC_GPT = read_data_and_labels(\"Vul_notPriorInCited\")\n",
    "preE, preE_DS, preE_GPT = read_data_and_labels(\"preE_qp\")\n",
    "\n",
    "len(VnotPinC), len(preE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_VnotPinC = [1 if str(x).lower() == \"true\" else 0 for x in VnotPinC['label']]\n",
    "ground_preE = [1 if str(x).lower() == \"true\" else 0 for x in preE['label']]\n",
    "preE_len = min(len(preE_DS), len(preE_GPT))\n",
    "ground_preE = ground_preE[:preE_len]\n",
    "labels_preE_DS = [1 if str(x).lower() == \"true\" else 0 for x in preE_DS.values()][:preE_len]\n",
    "labels_preE_GPT = [1 if str(x).lower() == \"true\" else 0 for x in preE_GPT.values()][:preE_len]\n",
    "labels_VnotPinC_DS = [1 if str(x).lower() == \"true\" else 0 for x in VnotPinC_DS.values()]\n",
    "labels_VnotPinC_GPT = [1 if str(x).lower() == \"true\" else 0 for x in VnotPinC_GPT.values()]\n",
    "labels_all_ground = ground_VnotPinC.copy()\n",
    "labels_all_ground.extend(ground_preE)\n",
    "labels_all_DS = labels_VnotPinC_DS.copy()\n",
    "labels_all_DS.extend(labels_preE_DS)\n",
    "labels_all_GPT = labels_VnotPinC_GPT.copy()\n",
    "labels_all_GPT.extend(labels_preE_GPT)\n",
    "\n",
    "verses_VnotPinC = [x for x in VnotPinC['verse_id']]\n",
    "verses_preE = [x for x in preE['verse_id']][:preE_len]\n",
    "verses_all = verses_VnotPinC.copy()\n",
    "verses_all.extend(verses_preE)\n",
    "\n",
    "mylabels = {'Vulgate_PriorNotInCited':ground_VnotPinC,\n",
    "            'pre-Elizabethan_qp':ground_preE,\n",
    "            'All':labels_all_ground}\n",
    "labels = {'labels_preE_DS':labels_preE_DS,\n",
    "          'labels_VnotPinC_DS':labels_VnotPinC_DS,\n",
    "          'labels_all_DS':labels_all_DS,\n",
    "          'labels_preE_GPT':labels_preE_GPT,\n",
    "          'labels_VnotPinC_GPT':labels_VnotPinC_GPT,\n",
    "          'labels_all_GPT':labels_all_GPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute evaluation stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = {labeled:{\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"F1_Score\": [],\n",
    "    \"Cohen's_Kappa\":[]\n",
    "}\n",
    " for labeled in mylabels.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for true_name, true_labels in mylabels.items():\n",
    "    for pred_name, pred_labels in labels.items():\n",
    "        if len(true_labels) == len(pred_labels):  \n",
    "            print(true_name, pred_name)\n",
    "            pred_name = pred_name.split(\"_\")[-1]\n",
    "            Accuracy = round(accuracy_score(true_labels, pred_labels),4)\n",
    "            Precision = round(precision_score(true_labels, pred_labels),4)\n",
    "            F1_Score = round(f1_score(true_labels, pred_labels),4)\n",
    "            kappa = round(cohen_kappa_score(true_labels,pred_labels),4)\n",
    "            tables[true_name][\"Model\"].append(pred_name)\n",
    "            tables[true_name][\"Accuracy\"].append(Accuracy)\n",
    "            tables[true_name][\"Precision\"].append(Precision)\n",
    "            tables[true_name][\"F1_Score\"].append(F1_Score)\n",
    "            tables[true_name][\"Cohen's_Kappa\"].append(kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Vulgate_PriorNotInCited 615 \n",
      "\n",
      "Model  Accuracy  Precision  F1_Score  Cohen's_Kappa\n",
      "   DS    0.8423     0.9554    0.8152         0.6827\n",
      "  GPT    0.7610     0.9529    0.6879         0.5174\n",
      "------------------------------------------------------\n",
      "pre-Elizabethan_qp 3000 \n",
      "\n",
      "Model  Accuracy  Precision  F1_Score  Cohen's_Kappa\n",
      "   DS    0.8777     0.9502    0.9235         0.6196\n",
      "  GPT    0.7903     0.9674    0.8580         0.4761\n",
      "------------------------------------------------------\n",
      "All 3615 \n",
      "\n",
      "Model  Accuracy  Precision  F1_Score  Cohen's_Kappa\n",
      "   DS    0.8716     0.9507    0.9128         0.6711\n",
      "  GPT    0.7853     0.9663    0.8417         0.5250\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------\")\n",
    "for name,data in tables.items(): \n",
    "    df = pd.DataFrame(data)\n",
    "    print(name,len(mylabels[name]),'\\n')\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_kappa = {}\n",
    "\n",
    "kappas = []\n",
    "for true_name, true_labels in mylabels.items():\n",
    "    if true_name != \"All\": continue \n",
    "    for pred_name, pred_labels in labels.items():\n",
    "        if len(true_labels) == len(pred_labels):  \n",
    "            kappa = round(cohen_kappa_score(true_labels,pred_labels),4)\n",
    "            kappas.append(kappa)\n",
    "            if \"DS\" in pred_name: \n",
    "                other_pred_labels = labels['labels_all_GPT']\n",
    "                kappa = round(cohen_kappa_score(pred_labels,other_pred_labels),4)\n",
    "                kappas.append(kappa) \n",
    "float(round(sum(kappas)/len(kappas),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verses = {'Vulgate_PriorNotInCited':verses_VnotPinC,\n",
    "            'pre-Elizabethan_qp':verses_preE,\n",
    "            'All':verses_all}\n",
    "\n",
    "for name, verse_set in verses.items():\n",
    "    for idx, id_string in enumerate(verse_set): \n",
    "        version, part, book = get_bible_info(id_string)\n",
    "        verses[name][idx] = (version,part,book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Version, 1 - Part, 2 - Book\n",
    "fidx_f = {0:'Version',1:'Part',2:'Book'}\n",
    "all_df = pd.DataFrame(columns=['Feature_Type','Feature','Model','Accuracy','Precision','F1_Score'])\n",
    "\n",
    "for fidx in [1,0,2]: \n",
    "    print(fidx_f[fidx])\n",
    "    for true_name, true_labels in mylabels.items(): \n",
    "        if \"All\" != true_name: continue \n",
    "        flist = [f[fidx] for f in verses[true_name]]\n",
    "        unique = list(set(flist))\n",
    "        specifics = {f:{\n",
    "                    \"Model\": [],\n",
    "                    \"Accuracy\": [],\n",
    "                    \"Precision\": [],\n",
    "                    \"F1_Score\": [],\n",
    "                    \"Cohen's Kappa\":[]\n",
    "                    } for f in unique} \n",
    "        for f in unique:\n",
    "            for pred_name, pred_labels in labels.items(): \n",
    "                if len(true_labels) != len(pred_labels): continue \n",
    "                pred_name = pred_name.split(\"_\")[-1]\n",
    "                indices = []\n",
    "                for i, item in enumerate(flist): \n",
    "                    if item == f: indices.append(i)\n",
    "                y_t = [true_labels[i] for i in indices]\n",
    "                y_p = [pred_labels[i] for i in indices]\n",
    "                Accuracy = round(accuracy_score(y_t, y_p),4)\n",
    "                Precision = round(precision_score(y_t, y_p),4)\n",
    "                F1_Score = round(f1_score(y_t, y_p),4)\n",
    "                kappa = round(cohen_kappa_score(y_t,y_p),4)\n",
    "                specifics[f][\"Model\"].append(pred_name)\n",
    "                specifics[f][\"Accuracy\"].append(Accuracy)\n",
    "                specifics[f][\"Precision\"].append(Precision)\n",
    "                specifics[f][\"F1_Score\"].append(F1_Score)\n",
    "                specifics[f][\"Cohen's Kappa\"].append(kappa)\n",
    "    for name,data in specifics.items(): \n",
    "        data['Feature'] = name\n",
    "        data['Feature_Type'] = fidx_f[fidx]\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.rename(columns = {'Dataset_Model':'Model'})\n",
    "        all_df = pd.concat([all_df,df],ignore_index=True)\n",
    "all_df.to_csv(f\"../assets/QP_labels/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Type</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Part</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>DS</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>GPT</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Part</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>DS</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.6639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Part</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>GPT</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Part</td>\n",
       "      <td>Apocrypha</td>\n",
       "      <td>DS</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.4865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Book</td>\n",
       "      <td>Ecclesiastes</td>\n",
       "      <td>GPT</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Book</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>DS</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Book</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>GPT</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Book</td>\n",
       "      <td>1 Maccabees</td>\n",
       "      <td>DS</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Book</td>\n",
       "      <td>1 Maccabees</td>\n",
       "      <td>GPT</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.1695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Type        Feature Model  Accuracy  Precision  F1_Score  \\\n",
       "0           Part  Old Testament    DS    0.8438     0.9333    0.8710   \n",
       "1           Part  Old Testament   GPT    0.7838     0.9425    0.8089   \n",
       "2           Part  New Testament    DS    0.8822     0.9538    0.9240   \n",
       "3           Part  New Testament   GPT    0.7896     0.9706    0.8522   \n",
       "4           Part      Apocrypha    DS    0.7286     0.9643    0.7397   \n",
       "..           ...            ...   ...       ...        ...       ...   \n",
       "145         Book   Ecclesiastes   GPT    0.7778     1.0000    0.8333   \n",
       "146         Book         Joshua    DS    1.0000     0.0000    0.0000   \n",
       "147         Book         Joshua   GPT    0.9000     0.0000    0.0000   \n",
       "148         Book    1 Maccabees    DS    0.4286     0.6667    0.3333   \n",
       "149         Book    1 Maccabees   GPT    0.5000     1.0000    0.3636   \n",
       "\n",
       "     Cohen's Kappa  \n",
       "0           0.6753  \n",
       "1           0.5713  \n",
       "2           0.6639  \n",
       "3           0.5052  \n",
       "4           0.4865  \n",
       "..             ...  \n",
       "145         0.5263  \n",
       "146            NaN  \n",
       "147         0.0000  \n",
       "148         0.0175  \n",
       "149         0.1695  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify mis-matches between myself & V3 for fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = {}\n",
    "\n",
    "# target_ground = ground_preE\n",
    "target_ground = VnotPinC\n",
    "\n",
    "for idx, label in enumerate(ground_preE): \n",
    "    V3_label = labels_preE_DS[idx]\n",
    "    if label != V3_label: \n",
    "        mismatches[idx] = (label,V3_label)\n",
    "\n",
    "mismatch_set = []\n",
    "targets = target_ground.to_dict(orient='records')\n",
    "for idx, entry in enumerate(targets): \n",
    "    version, part, book = get_bible_info(entry['verse_id'])\n",
    "    if idx in mismatches: \n",
    "        entry['label'] = mismatches[idx][0]\n",
    "        entry['V3_Label'] = mismatches[idx][1] \n",
    "        entry['index'] = idx \n",
    "        entry['Version'] = version\n",
    "        entry['Part'] = part \n",
    "        mismatch_set.append(entry)\n",
    "mismatch_set = pd.DataFrame(mismatch_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_set.to_csv(\"../assets/QP_labels/mismatches_preE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_set.to_csv(\"../assets/QP_labels/mismatches_VnotPinC.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
