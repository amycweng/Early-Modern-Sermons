{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibleMarginalia import * \n",
    "\n",
    "def get_marginal_notes(filepath):\n",
    "    tcp_id = filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    # read the input XML file \n",
    "    with open(filepath,'r') as file: \n",
    "        data = file.read()\n",
    "\n",
    "    # use soupstrainer to only parse the main body\n",
    "    tag = SoupStrainer(\"div1\")\n",
    "\n",
    "    # create a parsed tree, i.e., soup, of the body text using an html parser, which keeps track of line numbers\n",
    "    soup = BeautifulSoup(data,features=\"html.parser\",parse_only=tag)\n",
    "    \n",
    "    # iterate through every marginal note tag of this file \n",
    "    notes = soup.find_all('note')\n",
    "    notes_info = []\n",
    "    for note in notes: \n",
    "        if note.get(\"place\") == \"marg\":\n",
    "            div = note.parent\n",
    "            div_path = [] \n",
    "            while div is not None:\n",
    "                type = div.get(\"type\")\n",
    "                if type is not None: \n",
    "                    div_path.append(type) \n",
    "                div = div.parent\n",
    "            # find illegible parts and replace with the display characters \n",
    "            n = str(note)\n",
    "            for gap in note.find_all(\"gap\"):\n",
    "                n = re.sub(str(gap),gap[\"disp\"],n)\n",
    "            # strip out all embedded tags \n",
    "            n = re.sub(\"\\<(.*?)\\>\",\"\",n)\n",
    "            # remove newlines \n",
    "            n = re.sub(\"\\n\",\" \",n)\n",
    "            notes_info.append({\"tcp_id\": tcp_id, \n",
    "                             \"div_path\": \"; \".join(div_path),\n",
    "                             \"sourceline\": note.sourceline,\n",
    "                             \"sourcepos\":note.sourcepos,\n",
    "                             \"note\":n})\n",
    "    return notes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 texts\n",
      "Processed 200 texts\n",
      "Processed 300 texts\n",
      "Processed 400 texts\n",
      "Processed 500 texts\n",
      "Processed 600 texts\n",
      "Processed 700 texts\n",
      "Processed 800 texts\n",
      "Processed 900 texts\n",
      "Processed 1000 texts\n",
      "Processed 1100 texts\n",
      "Processed 1200 texts\n",
      "Processed 1300 texts\n",
      "Processed 1400 texts\n",
      "Processed 1500 texts\n",
      "Processed 1600 texts\n",
      "Processed 1700 texts\n",
      "Processed 1800 texts\n",
      "Processed 1900 texts\n",
      "Processed 2000 texts\n",
      "Processed 2100 texts\n",
      "Processed 2200 texts\n",
      "Processed 2300 texts\n",
      "Processed 2400 texts\n",
      "Processed 2500 texts\n",
      "Processed 2600 texts\n",
      "Processed 2700 texts\n",
      "Processed 2800 texts\n",
      "Processed 2900 texts\n",
      "Processed 3000 texts\n",
      "Processed 3100 texts\n",
      "Processed 3200 texts\n",
      "Processed 3300 texts\n",
      "Processed 3400 texts\n",
      "Processed 3500 texts\n",
      "Processed 3600 texts\n",
      "Processed 3700 texts\n",
      "Processed 3800 texts\n",
      "Processed 3900 texts\n",
      "Processed 4000 texts\n",
      "Processed 4100 texts\n",
      "Processed 4200 texts\n",
      "Processed 4300 texts\n",
      "Processed 4400 texts\n",
      "Processed 4500 texts\n",
      "Processed 4600 texts\n",
      "Processed 4700 texts\n",
      "Processed 4800 texts\n",
      "Processed 4900 texts\n",
      "Processed 5000 texts\n",
      "Processed 5100 texts\n",
      "Processed 5200 texts\n",
      "Processed 5300 texts\n",
      "Processed 5400 texts\n",
      "Processed 5500 texts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os,csv\n",
    "''' \n",
    "Takes 12 minutes \n",
    "'''\n",
    "sermons = pd.read_csv(\"sermons.csv\")[\"id\"]\n",
    "tcp = '/Users/amycweng/Digital Humanities/sermonsTCP'\n",
    "\n",
    "outfile = open(\"marginalia.csv\",\"w+\")\n",
    "writer = csv.DictWriter(outfile, fieldnames=[\"tcp_id\",\"div_path\",\"sourceline\",\"sourcepos\",\"note\"])\n",
    "writer.writeheader()\n",
    "no_notes = []\n",
    "count = 0\n",
    "for file in os.listdir(tcp): \n",
    "    filepath = os.path.join(tcp,file)\n",
    "    notes = get_marginal_notes(filepath)\n",
    "    tcp_id = file.split(\".\")[0]\n",
    "    if not len(notes): \n",
    "        no_notes.append(tcp_id)\n",
    "    else: \n",
    "        writer.writerows(notes)\n",
    "    count += 1 \n",
    "    if count % 100 == 0: \n",
    "        print(f\"Processed {count} texts\")\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435\n"
     ]
    }
   ],
   "source": [
    "print(len(no_notes)) # 1435 files in total, so there are 4000 texts with marginalia \n",
    "import json \n",
    "with open(\"no_notes.json\",\"w+\") as file: \n",
    "    json.dump(no_notes,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # replace all periods with spaces. This is to make sure that all citations are \n",
    "# # in the format of \"<book> <chapter> <verse>\", i.e., \"Ecclesiastes 9 4\". \n",
    "# # Some citations are originally inconsistently formatted as \"<book> <chapter>.<verse>\" at times \n",
    "# # and \"<book> <chapter>. <verse>.\" at other times, so replacing periods with spaces is the first step to standardizing all the citation formats \n",
    "# n = re.sub(r'(\\.)',r' ',n).lower()\n",
    "# remove everything that is not an alphabetical character, integer, comma, ampersand, illegible char, or a single space\n",
    "# n = re.sub(r'[^a-z0-9\\,\\&\\-\\â€”\\* ]','',n)\n",
    "# # replace all instances of \"and\" with ampersands \n",
    "# n = re.sub(rf\"\\band\\b|&ampc|&amp\",'&', n)\n",
    "# # next, replace all instances of two or more spaces with a single space. \n",
    "# n = re.sub(r'\\s+',' ',n).strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
